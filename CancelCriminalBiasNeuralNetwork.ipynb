{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DiGyt/snippets/blob/master/CancelCriminalBiasNeuralNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0YJrHxG4jwA",
        "outputId": "84ffc1b6-804c-450d-cf15-feb151361779"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'homeless-arrests-analysis' already exists and is not an empty directory.\n",
            "Archive:  /content/homeless-arrests-analysis/arrests.zip\n",
            "replace arrests.feather? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/datadesk/homeless-arrests-analysis.git\n",
        "!unzip /content/homeless-arrests-analysis/arrests.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9xAsAUI4tyq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "EqgEve5X4uDz",
        "outputId": "2c884ef7-50ac-44ad-ce2e-80897ffca83f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        booking_num  homeless  arrest_year  arrest_ymd booking_ymd gender  \\\n",
              "0           2497688       0.0       2011.0  2011-01-01  2011-01-01      M   \n",
              "1           2497689       0.0       2011.0  2011-01-01  2011-01-01      M   \n",
              "2           2497690       0.0       2011.0  2011-01-01  2011-01-01      M   \n",
              "3           2497697       0.0       2011.0  2011-01-01  2011-01-01      F   \n",
              "4           2497698       0.0       2011.0  2011-01-01  2011-01-01      M   \n",
              "...             ...       ...          ...         ...         ...    ...   \n",
              "743942      4870887       0.0       2016.0  2016-12-31  2017-01-01      M   \n",
              "743943      4870906       0.0       2016.0  2016-12-31  2017-01-01      M   \n",
              "743944      4871191       0.0       2016.0  2016-12-31  2017-01-01      M   \n",
              "743945      4871193       0.0       2016.0  2016-12-31  2017-01-01      M   \n",
              "743946      4871271       0.0       2016.0  2016-12-31  2017-01-01      M   \n",
              "\n",
              "       race   age       occupation  charge_code  \\\n",
              "0         W  25.0         ENGINEER   23152(A)VC   \n",
              "1         H  38.0            AGENT   23152(A)VC   \n",
              "2         W  25.0     BUSINESS DEV   23152(A)VC   \n",
              "3         W  40.0             NONE   273.5(A)PC   \n",
              "4         H  34.0          LABORER   12021(A)PC   \n",
              "...     ...   ...              ...          ...   \n",
              "743942    B  24.0          LABORER   12500(A)VC   \n",
              "743943    H  21.0          LABORER     484(A)PC   \n",
              "743944    H  19.0       UNEMPLOYED  148(A)(1)PC   \n",
              "743945    H  22.0  FORK LIFT DRIVE        236PC   \n",
              "743946    H  40.0         ASSEMBLY  245(A)(1)PC   \n",
              "\n",
              "                                    charge_desc  \n",
              "0                    drunk-driving-alcoholdrugs  \n",
              "1                    drunk-driving-alcoholdrugs  \n",
              "2                    drunk-driving-alcoholdrugs  \n",
              "3         corporal-injury-on-spousecohabitantet  \n",
              "4       poss-firearm-by-convictd-felonaddicte-1  \n",
              "...                                         ...  \n",
              "743942                        unlicensed-driver  \n",
              "743943                     grand-theft-over-400  \n",
              "743944                        resisting-officer  \n",
              "743945                       false-imprisonment  \n",
              "743946                        adw-wo-firearmgbi  \n",
              "\n",
              "[743947 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7f2bdac1-d651-4796-b2fd-4fce59403214\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>booking_num</th>\n",
              "      <th>homeless</th>\n",
              "      <th>arrest_year</th>\n",
              "      <th>arrest_ymd</th>\n",
              "      <th>booking_ymd</th>\n",
              "      <th>gender</th>\n",
              "      <th>race</th>\n",
              "      <th>age</th>\n",
              "      <th>occupation</th>\n",
              "      <th>charge_code</th>\n",
              "      <th>charge_desc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2497688</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2011.0</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>M</td>\n",
              "      <td>W</td>\n",
              "      <td>25.0</td>\n",
              "      <td>ENGINEER</td>\n",
              "      <td>23152(A)VC</td>\n",
              "      <td>drunk-driving-alcoholdrugs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2497689</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2011.0</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>M</td>\n",
              "      <td>H</td>\n",
              "      <td>38.0</td>\n",
              "      <td>AGENT</td>\n",
              "      <td>23152(A)VC</td>\n",
              "      <td>drunk-driving-alcoholdrugs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2497690</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2011.0</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>M</td>\n",
              "      <td>W</td>\n",
              "      <td>25.0</td>\n",
              "      <td>BUSINESS DEV</td>\n",
              "      <td>23152(A)VC</td>\n",
              "      <td>drunk-driving-alcoholdrugs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2497697</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2011.0</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>F</td>\n",
              "      <td>W</td>\n",
              "      <td>40.0</td>\n",
              "      <td>NONE</td>\n",
              "      <td>273.5(A)PC</td>\n",
              "      <td>corporal-injury-on-spousecohabitantet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2497698</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2011.0</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>M</td>\n",
              "      <td>H</td>\n",
              "      <td>34.0</td>\n",
              "      <td>LABORER</td>\n",
              "      <td>12021(A)PC</td>\n",
              "      <td>poss-firearm-by-convictd-felonaddicte-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>743942</th>\n",
              "      <td>4870887</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>2016-12-31</td>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>M</td>\n",
              "      <td>B</td>\n",
              "      <td>24.0</td>\n",
              "      <td>LABORER</td>\n",
              "      <td>12500(A)VC</td>\n",
              "      <td>unlicensed-driver</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>743943</th>\n",
              "      <td>4870906</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>2016-12-31</td>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>M</td>\n",
              "      <td>H</td>\n",
              "      <td>21.0</td>\n",
              "      <td>LABORER</td>\n",
              "      <td>484(A)PC</td>\n",
              "      <td>grand-theft-over-400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>743944</th>\n",
              "      <td>4871191</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>2016-12-31</td>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>M</td>\n",
              "      <td>H</td>\n",
              "      <td>19.0</td>\n",
              "      <td>UNEMPLOYED</td>\n",
              "      <td>148(A)(1)PC</td>\n",
              "      <td>resisting-officer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>743945</th>\n",
              "      <td>4871193</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>2016-12-31</td>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>M</td>\n",
              "      <td>H</td>\n",
              "      <td>22.0</td>\n",
              "      <td>FORK LIFT DRIVE</td>\n",
              "      <td>236PC</td>\n",
              "      <td>false-imprisonment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>743946</th>\n",
              "      <td>4871271</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>2016-12-31</td>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>M</td>\n",
              "      <td>H</td>\n",
              "      <td>40.0</td>\n",
              "      <td>ASSEMBLY</td>\n",
              "      <td>245(A)(1)PC</td>\n",
              "      <td>adw-wo-firearmgbi</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>743947 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f2bdac1-d651-4796-b2fd-4fce59403214')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7f2bdac1-d651-4796-b2fd-4fce59403214 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7f2bdac1-d651-4796-b2fd-4fce59403214');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ],
      "source": [
        "df = pd.read_feather(\"/content/arrests.feather\")\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssNmhmQIaJfe"
      },
      "outputs": [],
      "source": [
        "CODE_DICT = {\n",
        "              \"PC\": \"Penal Code\",\n",
        "              \"HS\": \"Health and Safety Code\",\n",
        "              \"VC\": \"Vehicle Code\",\n",
        "              #\"BP\": \"Business and Professions Code\",\n",
        "              #\"WI\": \"Welfare and Institutions Code\",\n",
        "              #\"RT\": \"Revenue and Taxation Code\",\n",
        "              #\"PU\": \"Public Utilitie Codes\",\n",
        "              #\"UI\": \"Unemployment Insurance Code\",\n",
        "              #\"IC\": \"Insurance Code\",\n",
        "              #\"US\": \"US Law?\",\n",
        "              #\"MC\": \"Municipal Code (Any City)\",\n",
        "             }\n",
        "\n",
        "def law_code(series):\n",
        "  out = []\n",
        "  for idx, field in enumerate(series):\n",
        "    cur = \"Other\"\n",
        "    for key, value in CODE_DICT.items():   \n",
        "      if key in str(field):\n",
        "        cur = value\n",
        "    out.append(cur)\n",
        "  return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meMl5FlRfAe6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ffd19a2-0193-4562-e436-254f935d0b7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "# create a mapping for the applied law code\n",
        "df[\"law_code\"] = law_code(df[\"charge_code\"])\n",
        "\n",
        "df[\"Penal Code\"] = df[\"law_code\"] == \"Penal Code\"\n",
        "df[\"Vehicle Code\"] = df[\"law_code\"] == \"Vehicle Code\"\n",
        "df[\"Health and Safety Code\"] = df[\"law_code\"] == \"Health and Safety Code\"\n",
        "\n",
        "# map race variables from letters to names\n",
        "r_map = dict({\"W\":\"White\", \"H\":\"Hispanic\", \"B\":\"Black\", \"A\":\"Other\"},\n",
        "             **{x:\"Other\" for x in (\"A\", \"C\", \"F\", \"I\", \"J\", \"K\", \"O\", \"P\")})\n",
        "df[\"race\"] = df[\"race\"].map(r_map)\n",
        "\n",
        "# rename seldomly occuring occuptations to \"Other\"\n",
        "df[\"occupation\"][df[\"occupation\"].isin(list(df.occupation.value_counts()[df.occupation.value_counts() < 1000].index))] = \"Other\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "hkq8oxr0j8x3",
        "outputId": "bc878a2c-ce37-4e86-a501-7c595ae683f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        booking_num  homeless  arrest_year  arrest_ymd booking_ymd gender  \\\n",
              "0           2497688       0.0       2011.0  2011-01-01  2011-01-01      M   \n",
              "1           2497689       0.0       2011.0  2011-01-01  2011-01-01      M   \n",
              "2           2497690       0.0       2011.0  2011-01-01  2011-01-01      M   \n",
              "3           2497697       0.0       2011.0  2011-01-01  2011-01-01      F   \n",
              "4           2497698       0.0       2011.0  2011-01-01  2011-01-01      M   \n",
              "...             ...       ...          ...         ...         ...    ...   \n",
              "743942      4870887       0.0       2016.0  2016-12-31  2017-01-01      M   \n",
              "743943      4870906       0.0       2016.0  2016-12-31  2017-01-01      M   \n",
              "743944      4871191       0.0       2016.0  2016-12-31  2017-01-01      M   \n",
              "743945      4871193       0.0       2016.0  2016-12-31  2017-01-01      M   \n",
              "743946      4871271       0.0       2016.0  2016-12-31  2017-01-01      M   \n",
              "\n",
              "            race   age  occupation  charge_code  \\\n",
              "0          White  25.0       Other   23152(A)VC   \n",
              "1       Hispanic  38.0       Other   23152(A)VC   \n",
              "2          White  25.0       Other   23152(A)VC   \n",
              "3          White  40.0        NONE   273.5(A)PC   \n",
              "4       Hispanic  34.0     LABORER   12021(A)PC   \n",
              "...          ...   ...         ...          ...   \n",
              "743942     Black  24.0     LABORER   12500(A)VC   \n",
              "743943  Hispanic  21.0     LABORER     484(A)PC   \n",
              "743944  Hispanic  19.0  UNEMPLOYED  148(A)(1)PC   \n",
              "743945  Hispanic  22.0       Other        236PC   \n",
              "743946  Hispanic  40.0       Other  245(A)(1)PC   \n",
              "\n",
              "                                    charge_desc      law_code  Penal Code  \\\n",
              "0                    drunk-driving-alcoholdrugs  Vehicle Code       False   \n",
              "1                    drunk-driving-alcoholdrugs  Vehicle Code       False   \n",
              "2                    drunk-driving-alcoholdrugs  Vehicle Code       False   \n",
              "3         corporal-injury-on-spousecohabitantet    Penal Code        True   \n",
              "4       poss-firearm-by-convictd-felonaddicte-1    Penal Code        True   \n",
              "...                                         ...           ...         ...   \n",
              "743942                        unlicensed-driver  Vehicle Code       False   \n",
              "743943                     grand-theft-over-400    Penal Code        True   \n",
              "743944                        resisting-officer    Penal Code        True   \n",
              "743945                       false-imprisonment    Penal Code        True   \n",
              "743946                        adw-wo-firearmgbi    Penal Code        True   \n",
              "\n",
              "        Vehicle Code  Health and Safety Code  \n",
              "0               True                   False  \n",
              "1               True                   False  \n",
              "2               True                   False  \n",
              "3              False                   False  \n",
              "4              False                   False  \n",
              "...              ...                     ...  \n",
              "743942          True                   False  \n",
              "743943         False                   False  \n",
              "743944         False                   False  \n",
              "743945         False                   False  \n",
              "743946         False                   False  \n",
              "\n",
              "[743947 rows x 15 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3a121948-df35-4f1d-971b-efdba76ee7a9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>booking_num</th>\n",
              "      <th>homeless</th>\n",
              "      <th>arrest_year</th>\n",
              "      <th>arrest_ymd</th>\n",
              "      <th>booking_ymd</th>\n",
              "      <th>gender</th>\n",
              "      <th>race</th>\n",
              "      <th>age</th>\n",
              "      <th>occupation</th>\n",
              "      <th>charge_code</th>\n",
              "      <th>charge_desc</th>\n",
              "      <th>law_code</th>\n",
              "      <th>Penal Code</th>\n",
              "      <th>Vehicle Code</th>\n",
              "      <th>Health and Safety Code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2497688</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2011.0</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>M</td>\n",
              "      <td>White</td>\n",
              "      <td>25.0</td>\n",
              "      <td>Other</td>\n",
              "      <td>23152(A)VC</td>\n",
              "      <td>drunk-driving-alcoholdrugs</td>\n",
              "      <td>Vehicle Code</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2497689</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2011.0</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>M</td>\n",
              "      <td>Hispanic</td>\n",
              "      <td>38.0</td>\n",
              "      <td>Other</td>\n",
              "      <td>23152(A)VC</td>\n",
              "      <td>drunk-driving-alcoholdrugs</td>\n",
              "      <td>Vehicle Code</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2497690</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2011.0</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>M</td>\n",
              "      <td>White</td>\n",
              "      <td>25.0</td>\n",
              "      <td>Other</td>\n",
              "      <td>23152(A)VC</td>\n",
              "      <td>drunk-driving-alcoholdrugs</td>\n",
              "      <td>Vehicle Code</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2497697</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2011.0</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>F</td>\n",
              "      <td>White</td>\n",
              "      <td>40.0</td>\n",
              "      <td>NONE</td>\n",
              "      <td>273.5(A)PC</td>\n",
              "      <td>corporal-injury-on-spousecohabitantet</td>\n",
              "      <td>Penal Code</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2497698</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2011.0</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>M</td>\n",
              "      <td>Hispanic</td>\n",
              "      <td>34.0</td>\n",
              "      <td>LABORER</td>\n",
              "      <td>12021(A)PC</td>\n",
              "      <td>poss-firearm-by-convictd-felonaddicte-1</td>\n",
              "      <td>Penal Code</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>743942</th>\n",
              "      <td>4870887</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>2016-12-31</td>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>M</td>\n",
              "      <td>Black</td>\n",
              "      <td>24.0</td>\n",
              "      <td>LABORER</td>\n",
              "      <td>12500(A)VC</td>\n",
              "      <td>unlicensed-driver</td>\n",
              "      <td>Vehicle Code</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>743943</th>\n",
              "      <td>4870906</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>2016-12-31</td>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>M</td>\n",
              "      <td>Hispanic</td>\n",
              "      <td>21.0</td>\n",
              "      <td>LABORER</td>\n",
              "      <td>484(A)PC</td>\n",
              "      <td>grand-theft-over-400</td>\n",
              "      <td>Penal Code</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>743944</th>\n",
              "      <td>4871191</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>2016-12-31</td>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>M</td>\n",
              "      <td>Hispanic</td>\n",
              "      <td>19.0</td>\n",
              "      <td>UNEMPLOYED</td>\n",
              "      <td>148(A)(1)PC</td>\n",
              "      <td>resisting-officer</td>\n",
              "      <td>Penal Code</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>743945</th>\n",
              "      <td>4871193</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>2016-12-31</td>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>M</td>\n",
              "      <td>Hispanic</td>\n",
              "      <td>22.0</td>\n",
              "      <td>Other</td>\n",
              "      <td>236PC</td>\n",
              "      <td>false-imprisonment</td>\n",
              "      <td>Penal Code</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>743946</th>\n",
              "      <td>4871271</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>2016-12-31</td>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>M</td>\n",
              "      <td>Hispanic</td>\n",
              "      <td>40.0</td>\n",
              "      <td>Other</td>\n",
              "      <td>245(A)(1)PC</td>\n",
              "      <td>adw-wo-firearmgbi</td>\n",
              "      <td>Penal Code</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>743947 rows × 15 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a121948-df35-4f1d-971b-efdba76ee7a9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3a121948-df35-4f1d-971b-efdba76ee7a9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3a121948-df35-4f1d-971b-efdba76ee7a9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "jr1MPcq970EU",
        "outputId": "11fa847b-e597-4532-c487-7f68592cf77e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fafa1090e10>"
            ]
          },
          "metadata": {},
          "execution_count": 135
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 936x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "\n",
        "df_count = df.groupby([\"race\", \"law_code\"]).size().to_frame(name = 'size').reset_index()\n",
        "\n",
        "plt.figure(figsize=(13, 8))\n",
        "sns.barplot(x=\"law_code\", y=\"size\", hue=\"race\", data=df_count,\n",
        "            order=[\"Penal Code\", \"Vehicle Code\", \"Health and Safety Code\", \"Other\"],\n",
        "            hue_order=[\"Black\", \"Hispanic\", \"White\", \"Other\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRHQAVFs6zu_",
        "outputId": "4b25b352-7caa-4817-c01e-9bf7af554a93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Black       0.057874\n",
              "Hispanic   -0.133712\n",
              "Other      -0.043758\n",
              "White       0.126320\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ],
      "source": [
        "pd.get_dummies(df[\"race\"]).corrwith(df[\"homeless\"], method=\"spearman\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNRPzaOQ_B09"
      },
      "outputs": [],
      "source": [
        "x = np.concatenate([pd.get_dummies(df[\"occupation\"]).to_numpy(),\n",
        "                    df[[\"homeless\", \"age\"]]], axis=1).astype(float)\n",
        "\n",
        "y = df[\"Penal Code\"].to_numpy().astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9_iP56FEYkS"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "                              tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "                              tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "                              tf.keras.layers.Dense(32, activation=\"relu\"),\n",
        "                              tf.keras.layers.Dense(8, activation=\"relu\"),\n",
        "                              tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
        "                              ])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "              loss = \"BCE\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLUFYJIOEgsf",
        "outputId": "f6098388-df91-4b98-ee9d-8bacdfe957c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "2325/2325 [==============================] - 9s 4ms/step - loss: 0.6717 - accuracy: 0.5888 - val_loss: 0.6501 - val_accuracy: 0.6340\n",
            "Epoch 2/20\n",
            "2325/2325 [==============================] - 8s 4ms/step - loss: 0.6683 - accuracy: 0.5945 - val_loss: 0.6421 - val_accuracy: 0.6398\n",
            "Epoch 3/20\n",
            "2325/2325 [==============================] - 8s 4ms/step - loss: 0.6663 - accuracy: 0.5972 - val_loss: 0.6396 - val_accuracy: 0.6419\n",
            "Epoch 4/20\n",
            "2325/2325 [==============================] - 9s 4ms/step - loss: 0.6657 - accuracy: 0.5981 - val_loss: 0.6455 - val_accuracy: 0.6396\n",
            "Epoch 5/20\n",
            "2325/2325 [==============================] - 9s 4ms/step - loss: 0.6654 - accuracy: 0.5981 - val_loss: 0.6464 - val_accuracy: 0.6398\n",
            "Epoch 6/20\n",
            "2325/2325 [==============================] - 8s 4ms/step - loss: 0.6653 - accuracy: 0.5985 - val_loss: 0.6422 - val_accuracy: 0.6409\n",
            "Epoch 7/20\n",
            "2325/2325 [==============================] - 9s 4ms/step - loss: 0.6652 - accuracy: 0.5983 - val_loss: 0.6434 - val_accuracy: 0.6407\n",
            "Epoch 8/20\n",
            "2325/2325 [==============================] - 8s 4ms/step - loss: 0.6651 - accuracy: 0.5984 - val_loss: 0.6410 - val_accuracy: 0.6417\n",
            "Epoch 9/20\n",
            "2325/2325 [==============================] - 9s 4ms/step - loss: 0.6651 - accuracy: 0.5985 - val_loss: 0.6439 - val_accuracy: 0.6399\n",
            "Epoch 10/20\n",
            "2325/2325 [==============================] - 8s 4ms/step - loss: 0.6650 - accuracy: 0.5987 - val_loss: 0.6493 - val_accuracy: 0.6365\n",
            "Epoch 11/20\n",
            "2325/2325 [==============================] - 11s 5ms/step - loss: 0.6650 - accuracy: 0.5984 - val_loss: 0.6436 - val_accuracy: 0.6403\n",
            "Epoch 12/20\n",
            "2325/2325 [==============================] - 8s 4ms/step - loss: 0.6649 - accuracy: 0.5988 - val_loss: 0.6471 - val_accuracy: 0.6381\n",
            "Epoch 13/20\n",
            "2325/2325 [==============================] - 9s 4ms/step - loss: 0.6649 - accuracy: 0.5986 - val_loss: 0.6428 - val_accuracy: 0.6395\n",
            "Epoch 14/20\n",
            "2325/2325 [==============================] - 8s 4ms/step - loss: 0.6649 - accuracy: 0.5986 - val_loss: 0.6444 - val_accuracy: 0.6401\n",
            "Epoch 15/20\n",
            "2325/2325 [==============================] - 8s 4ms/step - loss: 0.6648 - accuracy: 0.5986 - val_loss: 0.6415 - val_accuracy: 0.6418\n",
            "Epoch 16/20\n",
            "2325/2325 [==============================] - 8s 4ms/step - loss: 0.6648 - accuracy: 0.5985 - val_loss: 0.6431 - val_accuracy: 0.6392\n",
            "Epoch 17/20\n",
            "2325/2325 [==============================] - 9s 4ms/step - loss: 0.6648 - accuracy: 0.5984 - val_loss: 0.6455 - val_accuracy: 0.6394\n",
            "Epoch 18/20\n",
            "2325/2325 [==============================] - 8s 4ms/step - loss: 0.6648 - accuracy: 0.5986 - val_loss: 0.6482 - val_accuracy: 0.6382\n",
            "Epoch 19/20\n",
            "2325/2325 [==============================] - 9s 4ms/step - loss: 0.6647 - accuracy: 0.5987 - val_loss: 0.6455 - val_accuracy: 0.6388\n",
            "Epoch 20/20\n",
            "2325/2325 [==============================] - 8s 4ms/step - loss: 0.6647 - accuracy: 0.5987 - val_loss: 0.6434 - val_accuracy: 0.6391\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faf944da790>"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ],
      "source": [
        "model.fit(x, y[:, None], validation_split=0.2, batch_size=256, shuffle=True, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.get_dummies(df[\"race\"]).corrwith(pd.Series(model(x)[:, 0]), method=\"spearman\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f54TJnWcNX0o",
        "outputId": "e0a4a1f7-be28-4646-b555-5a290ce4ce88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Black       0.123140\n",
              "Hispanic   -0.104760\n",
              "Other      -0.068310\n",
              "White       0.024499\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dz4xYYeqIMFH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e543957e-a323-49de-ce10-979510f93f4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "# concatenate a one hot encoding of the race variable into our loss\n",
        "y_m = np.concatenate([df[\"Penal Code\"][:, np.newaxis], pd.get_dummies(df[\"race\"])], axis=1).astype(float)\n",
        "\n",
        "def bias_loss(y_true, y_pred):\n",
        "  return tf.keras.losses.binary_crossentropy(y_true[:, :1], y_pred) * (tf.math.reduce_prod([tf.math.abs(tfp.stats.correlation(y_true[:, i:i+1], y_pred)) for i in range(1, y_true.shape[1])]) + 0.01)  #* tf.math.abs(tfp.stats.correlation(y_true[:, 1:], y_pred))  #/ tf.keras.losses.kullback_leibler_divergence(y_true[:, 1], y_pred)\n",
        "\n",
        "def bias_acc(y_true, y_pred):\n",
        "  return tf.keras.metrics.binary_accuracy(y_true[:, :1], y_pred)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "                              tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "                              tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "                              tf.keras.layers.Dense(32, activation=\"relu\"),\n",
        "                              tf.keras.layers.Dense(8, activation=\"relu\"),\n",
        "                              tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
        "                              ])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "              loss=bias_loss, metrics=bias_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eU_JdSeuIMJ9",
        "outputId": "5b5f7eb8-67cf-41c8-936f-f2702626fd84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "2325/2325 [==============================] - 18s 7ms/step - loss: 0.0068 - bias_acc: 0.5797 - val_loss: nan - val_bias_acc: 0.5704\n",
            "Epoch 2/20\n",
            "2325/2325 [==============================] - 15s 6ms/step - loss: 0.0067 - bias_acc: 0.5889 - val_loss: nan - val_bias_acc: 0.6229\n",
            "Epoch 3/20\n",
            "2325/2325 [==============================] - 15s 6ms/step - loss: 0.0067 - bias_acc: 0.5906 - val_loss: nan - val_bias_acc: 0.6112\n",
            "Epoch 4/20\n",
            "2325/2325 [==============================] - 15s 6ms/step - loss: 0.0067 - bias_acc: 0.5933 - val_loss: nan - val_bias_acc: 0.6412\n",
            "Epoch 5/20\n",
            "2325/2325 [==============================] - 15s 6ms/step - loss: 0.0067 - bias_acc: 0.5951 - val_loss: nan - val_bias_acc: 0.6331\n",
            "Epoch 6/20\n",
            "2325/2325 [==============================] - 15s 6ms/step - loss: 0.0067 - bias_acc: 0.5960 - val_loss: nan - val_bias_acc: 0.6393\n",
            "Epoch 7/20\n",
            "2325/2325 [==============================] - 16s 7ms/step - loss: 0.0067 - bias_acc: 0.5969 - val_loss: nan - val_bias_acc: 0.6401\n",
            "Epoch 8/20\n",
            "2325/2325 [==============================] - 15s 6ms/step - loss: 0.0067 - bias_acc: 0.5972 - val_loss: nan - val_bias_acc: 0.6398\n",
            "Epoch 9/20\n",
            "2325/2325 [==============================] - 15s 6ms/step - loss: 0.0067 - bias_acc: 0.5975 - val_loss: nan - val_bias_acc: 0.6398\n",
            "Epoch 10/20\n",
            "2325/2325 [==============================] - 15s 6ms/step - loss: 0.0067 - bias_acc: 0.5975 - val_loss: nan - val_bias_acc: 0.6402\n",
            "Epoch 11/20\n",
            "2325/2325 [==============================] - 16s 7ms/step - loss: 0.0067 - bias_acc: 0.5974 - val_loss: nan - val_bias_acc: 0.6396\n",
            "Epoch 12/20\n",
            "2325/2325 [==============================] - 15s 6ms/step - loss: 0.0067 - bias_acc: 0.5978 - val_loss: nan - val_bias_acc: 0.6397\n",
            "Epoch 13/20\n",
            "2325/2325 [==============================] - 15s 6ms/step - loss: 0.0067 - bias_acc: 0.5978 - val_loss: nan - val_bias_acc: 0.6408\n",
            "Epoch 14/20\n",
            "2325/2325 [==============================] - 15s 6ms/step - loss: 0.0067 - bias_acc: 0.5977 - val_loss: nan - val_bias_acc: 0.6390\n",
            "Epoch 15/20\n",
            "2325/2325 [==============================] - 15s 6ms/step - loss: 0.0067 - bias_acc: 0.5977 - val_loss: nan - val_bias_acc: 0.6403\n",
            "Epoch 16/20\n",
            "2325/2325 [==============================] - 15s 7ms/step - loss: 0.0067 - bias_acc: 0.5973 - val_loss: nan - val_bias_acc: 0.6412\n",
            "Epoch 17/20\n",
            "2325/2325 [==============================] - 15s 6ms/step - loss: 0.0067 - bias_acc: 0.5980 - val_loss: nan - val_bias_acc: 0.6398\n",
            "Epoch 18/20\n",
            "2325/2325 [==============================] - 15s 6ms/step - loss: 0.0067 - bias_acc: 0.5979 - val_loss: nan - val_bias_acc: 0.6414\n",
            "Epoch 19/20\n",
            "2325/2325 [==============================] - 15s 6ms/step - loss: 0.0067 - bias_acc: 0.5982 - val_loss: nan - val_bias_acc: 0.6406\n",
            "Epoch 20/20\n",
            "2325/2325 [==============================] - 15s 6ms/step - loss: 0.0067 - bias_acc: 0.5981 - val_loss: nan - val_bias_acc: 0.6394\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faf11c2e790>"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ],
      "source": [
        "model.fit(x, y_m, validation_split=0.2, batch_size=256, shuffle=True, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.get_dummies(df[\"race\"]).corrwith(pd.Series(model(x)[:, 0]), method=\"spearman\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9HtqVMoOXb9",
        "outputId": "3e944538-50e1-47aa-cf89-28a23bccd15a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Black       0.077009\n",
              "Hispanic   -0.039611\n",
              "Other      -0.067603\n",
              "White      -0.003479\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aKH5ksUyUhaK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "id": "ibIvVLq0l0xS",
        "outputId": "242919b0-f721-4790-b787-435f585467ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-29 12:41:23--  https://www.openintro.org/data/csv/satgpa.csv\n",
            "Resolving www.openintro.org (www.openintro.org)... 192.185.65.127\n",
            "Connecting to www.openintro.org (www.openintro.org)|192.185.65.127|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20106 (20K) [text/csv]\n",
            "Saving to: ‘satgpa.csv.3’\n",
            "\n",
            "satgpa.csv.3        100%[===================>]  19.63K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2022-06-29 12:41:23 (302 KB/s) - ‘satgpa.csv.3’ saved [20106/20106]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sex  sat_v  sat_m  sat_sum  hs_gpa  fy_gpa\n",
              "0      1     65     62      127    3.40    3.18\n",
              "1      2     58     64      122    4.00    3.33\n",
              "2      2     56     60      116    3.75    3.25\n",
              "3      1     42     53       95    3.75    2.42\n",
              "4      1     55     52      107    4.00    2.63\n",
              "..   ...    ...    ...      ...     ...     ...\n",
              "995    2     50     50      100    3.70    2.19\n",
              "996    1     54     54      108    3.30    1.50\n",
              "997    1     56     58      114    3.50    3.17\n",
              "998    1     55     65      120    2.30    1.94\n",
              "999    1     49     44       93    2.70    2.38\n",
              "\n",
              "[1000 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b79916af-a671-4088-a78c-254ef604e6e3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sex</th>\n",
              "      <th>sat_v</th>\n",
              "      <th>sat_m</th>\n",
              "      <th>sat_sum</th>\n",
              "      <th>hs_gpa</th>\n",
              "      <th>fy_gpa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>65</td>\n",
              "      <td>62</td>\n",
              "      <td>127</td>\n",
              "      <td>3.40</td>\n",
              "      <td>3.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>58</td>\n",
              "      <td>64</td>\n",
              "      <td>122</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>56</td>\n",
              "      <td>60</td>\n",
              "      <td>116</td>\n",
              "      <td>3.75</td>\n",
              "      <td>3.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>53</td>\n",
              "      <td>95</td>\n",
              "      <td>3.75</td>\n",
              "      <td>2.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>55</td>\n",
              "      <td>52</td>\n",
              "      <td>107</td>\n",
              "      <td>4.00</td>\n",
              "      <td>2.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>2</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>100</td>\n",
              "      <td>3.70</td>\n",
              "      <td>2.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>1</td>\n",
              "      <td>54</td>\n",
              "      <td>54</td>\n",
              "      <td>108</td>\n",
              "      <td>3.30</td>\n",
              "      <td>1.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>1</td>\n",
              "      <td>56</td>\n",
              "      <td>58</td>\n",
              "      <td>114</td>\n",
              "      <td>3.50</td>\n",
              "      <td>3.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>1</td>\n",
              "      <td>55</td>\n",
              "      <td>65</td>\n",
              "      <td>120</td>\n",
              "      <td>2.30</td>\n",
              "      <td>1.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>1</td>\n",
              "      <td>49</td>\n",
              "      <td>44</td>\n",
              "      <td>93</td>\n",
              "      <td>2.70</td>\n",
              "      <td>2.38</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b79916af-a671-4088-a78c-254ef604e6e3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b79916af-a671-4088-a78c-254ef604e6e3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b79916af-a671-4088-a78c-254ef604e6e3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ],
      "source": [
        "!wget https://www.openintro.org/data/csv/satgpa.csv\n",
        "\n",
        "df = pd.read_csv(\"satgpa.csv\")\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxAO0IufmANR"
      },
      "outputs": [],
      "source": [
        "\n",
        "t = df[[\"sat_sum\"]].to_numpy(dtype=float)\n",
        "t_m = df[[\"sat_sum\", \"sex\"]].to_numpy(dtype=float)\n",
        "x = df[[\"hs_gpa\", \"fy_gpa\", \"sex\"]].to_numpy(dtype=float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "681fe8QMo8mn"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "                              tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "                              tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "                              tf.keras.layers.Dense(32, activation=\"relu\"),\n",
        "                              tf.keras.layers.Dense(8, activation=\"relu\"),\n",
        "                              tf.keras.layers.Dense(1, activation=None),\n",
        "                              ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afunmTfrpmJ9"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "              loss = \"MSE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgCJLd3Lp-IM",
        "outputId": "54402673-2e92-4fe7-db3a-6aaae3b3308f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "15/15 [==============================] - 1s 11ms/step - loss: 10502.5420 - val_loss: 10659.2246\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 9587.6846 - val_loss: 9245.6201\n",
            "Epoch 3/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 7570.8267 - val_loss: 6170.5786\n",
            "Epoch 4/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3745.7124 - val_loss: 1574.8199\n",
            "Epoch 5/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 574.3622 - val_loss: 396.8309\n",
            "Epoch 6/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 383.7199 - val_loss: 331.3428\n",
            "Epoch 7/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 301.2933 - val_loss: 350.3752\n",
            "Epoch 8/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 289.1054 - val_loss: 304.7496\n",
            "Epoch 9/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 286.0201 - val_loss: 311.8619\n",
            "Epoch 10/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 281.1704 - val_loss: 311.0406\n",
            "Epoch 11/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 277.7594 - val_loss: 298.6996\n",
            "Epoch 12/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 276.0862 - val_loss: 301.2646\n",
            "Epoch 13/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 271.1321 - val_loss: 299.9650\n",
            "Epoch 14/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 270.3322 - val_loss: 296.9495\n",
            "Epoch 15/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 264.0268 - val_loss: 281.9379\n",
            "Epoch 16/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 261.2905 - val_loss: 286.9221\n",
            "Epoch 17/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 258.3627 - val_loss: 279.8415\n",
            "Epoch 18/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 254.2026 - val_loss: 273.5754\n",
            "Epoch 19/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 253.4359 - val_loss: 271.5045\n",
            "Epoch 20/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 247.4439 - val_loss: 268.7764\n",
            "Epoch 21/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 244.9168 - val_loss: 260.9783\n",
            "Epoch 22/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 240.5340 - val_loss: 261.7190\n",
            "Epoch 23/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 235.1104 - val_loss: 256.6679\n",
            "Epoch 24/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 231.4903 - val_loss: 250.4051\n",
            "Epoch 25/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 228.0645 - val_loss: 254.5781\n",
            "Epoch 26/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 225.1712 - val_loss: 236.0845\n",
            "Epoch 27/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 225.6389 - val_loss: 249.4598\n",
            "Epoch 28/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 218.7172 - val_loss: 226.1319\n",
            "Epoch 29/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 216.4334 - val_loss: 229.6736\n",
            "Epoch 30/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 210.9341 - val_loss: 223.0004\n",
            "Epoch 31/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 207.8864 - val_loss: 240.1575\n",
            "Epoch 32/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 216.3256 - val_loss: 205.0002\n",
            "Epoch 33/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 213.8457 - val_loss: 249.0942\n",
            "Epoch 34/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 201.0783 - val_loss: 204.3484\n",
            "Epoch 35/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 197.6560 - val_loss: 213.5093\n",
            "Epoch 36/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 195.7920 - val_loss: 207.3809\n",
            "Epoch 37/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 193.9206 - val_loss: 197.1729\n",
            "Epoch 38/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 189.4431 - val_loss: 203.0225\n",
            "Epoch 39/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 188.1306 - val_loss: 189.6739\n",
            "Epoch 40/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 186.6979 - val_loss: 201.4557\n",
            "Epoch 41/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 184.9119 - val_loss: 183.5769\n",
            "Epoch 42/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 184.0108 - val_loss: 213.1985\n",
            "Epoch 43/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 182.6091 - val_loss: 189.2774\n",
            "Epoch 44/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 177.8583 - val_loss: 190.9174\n",
            "Epoch 45/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 177.2919 - val_loss: 179.4565\n",
            "Epoch 46/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 175.0390 - val_loss: 189.5492\n",
            "Epoch 47/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 174.4626 - val_loss: 173.2089\n",
            "Epoch 48/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 172.1608 - val_loss: 180.3301\n",
            "Epoch 49/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 169.8938 - val_loss: 169.3871\n",
            "Epoch 50/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 172.3503 - val_loss: 182.0345\n",
            "Epoch 51/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 167.3062 - val_loss: 177.2744\n",
            "Epoch 52/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 165.9478 - val_loss: 179.8723\n",
            "Epoch 53/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 165.3423 - val_loss: 170.3849\n",
            "Epoch 54/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 163.3519 - val_loss: 171.5773\n",
            "Epoch 55/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 161.5617 - val_loss: 180.6528\n",
            "Epoch 56/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 161.8300 - val_loss: 163.1347\n",
            "Epoch 57/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 160.5237 - val_loss: 168.7723\n",
            "Epoch 58/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 158.1924 - val_loss: 166.3645\n",
            "Epoch 59/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 158.0793 - val_loss: 159.8166\n",
            "Epoch 60/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 157.4017 - val_loss: 169.9395\n",
            "Epoch 61/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 154.5775 - val_loss: 174.7211\n",
            "Epoch 62/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 153.8094 - val_loss: 161.0244\n",
            "Epoch 63/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 154.5164 - val_loss: 168.4726\n",
            "Epoch 64/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 151.2525 - val_loss: 170.7493\n",
            "Epoch 65/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 154.0120 - val_loss: 156.1389\n",
            "Epoch 66/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 149.5879 - val_loss: 169.6868\n",
            "Epoch 67/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 151.0112 - val_loss: 155.4490\n",
            "Epoch 68/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 147.9843 - val_loss: 165.7388\n",
            "Epoch 69/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 147.3276 - val_loss: 172.7736\n",
            "Epoch 70/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 148.7898 - val_loss: 154.2443\n",
            "Epoch 71/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 146.4387 - val_loss: 157.9020\n",
            "Epoch 72/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 145.7856 - val_loss: 157.5352\n",
            "Epoch 73/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 144.2477 - val_loss: 159.2948\n",
            "Epoch 74/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 144.6911 - val_loss: 155.1708\n",
            "Epoch 75/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 142.9689 - val_loss: 162.9844\n",
            "Epoch 76/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 144.9472 - val_loss: 171.1346\n",
            "Epoch 77/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 142.2393 - val_loss: 162.5546\n",
            "Epoch 78/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 146.8060 - val_loss: 170.3748\n",
            "Epoch 79/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 143.9389 - val_loss: 155.8477\n",
            "Epoch 80/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 140.4564 - val_loss: 159.3139\n",
            "Epoch 81/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 139.9047 - val_loss: 155.1854\n",
            "Epoch 82/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 140.2058 - val_loss: 151.9301\n",
            "Epoch 83/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 141.2876 - val_loss: 160.8985\n",
            "Epoch 84/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 139.7307 - val_loss: 163.8009\n",
            "Epoch 85/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 140.4444 - val_loss: 162.3155\n",
            "Epoch 86/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 141.4125 - val_loss: 162.4758\n",
            "Epoch 87/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.7430 - val_loss: 154.0246\n",
            "Epoch 88/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 140.5021 - val_loss: 167.1378\n",
            "Epoch 89/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 137.7817 - val_loss: 172.1763\n",
            "Epoch 90/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 144.3855 - val_loss: 151.3277\n",
            "Epoch 91/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.7008 - val_loss: 156.0479\n",
            "Epoch 92/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.8519 - val_loss: 154.8407\n",
            "Epoch 93/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.8236 - val_loss: 155.3082\n",
            "Epoch 94/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.3538 - val_loss: 172.4216\n",
            "Epoch 95/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.4974 - val_loss: 170.9609\n",
            "Epoch 96/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 142.6130 - val_loss: 153.2440\n",
            "Epoch 97/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.6295 - val_loss: 155.9023\n",
            "Epoch 98/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.6424 - val_loss: 159.7364\n",
            "Epoch 99/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.3351 - val_loss: 162.5868\n",
            "Epoch 100/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 138.0751 - val_loss: 181.3040\n",
            "Epoch 101/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 140.6454 - val_loss: 160.3664\n",
            "Epoch 102/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.3798 - val_loss: 156.1698\n",
            "Epoch 103/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.9325 - val_loss: 156.5511\n",
            "Epoch 104/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 138.9629 - val_loss: 163.2198\n",
            "Epoch 105/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 136.2393 - val_loss: 162.8306\n",
            "Epoch 106/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 138.9010 - val_loss: 153.0345\n",
            "Epoch 107/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.7569 - val_loss: 151.8421\n",
            "Epoch 108/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 144.1689 - val_loss: 158.8960\n",
            "Epoch 109/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.2467 - val_loss: 164.6645\n",
            "Epoch 110/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.2528 - val_loss: 156.4104\n",
            "Epoch 111/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.5723 - val_loss: 154.9810\n",
            "Epoch 112/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.5355 - val_loss: 181.3432\n",
            "Epoch 113/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 138.6881 - val_loss: 166.8256\n",
            "Epoch 114/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.6162 - val_loss: 153.7425\n",
            "Epoch 115/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.4266 - val_loss: 155.5699\n",
            "Epoch 116/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.3617 - val_loss: 161.2879\n",
            "Epoch 117/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.9462 - val_loss: 164.4065\n",
            "Epoch 118/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.4374 - val_loss: 162.9711\n",
            "Epoch 119/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 138.0013 - val_loss: 164.8890\n",
            "Epoch 120/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.2025 - val_loss: 174.9295\n",
            "Epoch 121/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.7916 - val_loss: 156.6909\n",
            "Epoch 122/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 140.9370 - val_loss: 161.8279\n",
            "Epoch 123/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.0285 - val_loss: 164.5891\n",
            "Epoch 124/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.4593 - val_loss: 173.5091\n",
            "Epoch 125/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.5309 - val_loss: 152.5060\n",
            "Epoch 126/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 140.9510 - val_loss: 152.4516\n",
            "Epoch 127/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 141.5592 - val_loss: 157.9781\n",
            "Epoch 128/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.8525 - val_loss: 154.8169\n",
            "Epoch 129/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.7646 - val_loss: 155.3111\n",
            "Epoch 130/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.5767 - val_loss: 165.2703\n",
            "Epoch 131/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.2304 - val_loss: 166.4198\n",
            "Epoch 132/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.0063 - val_loss: 166.5914\n",
            "Epoch 133/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 138.9377 - val_loss: 156.0535\n",
            "Epoch 134/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.6715 - val_loss: 171.8523\n",
            "Epoch 135/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 137.2754 - val_loss: 158.9241\n",
            "Epoch 136/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 138.8985 - val_loss: 158.2205\n",
            "Epoch 137/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.9446 - val_loss: 171.0538\n",
            "Epoch 138/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 139.4539 - val_loss: 161.6671\n",
            "Epoch 139/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.9158 - val_loss: 151.1131\n",
            "Epoch 140/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 141.2587 - val_loss: 167.4023\n",
            "Epoch 141/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.4191 - val_loss: 169.5012\n",
            "Epoch 142/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.6764 - val_loss: 179.9578\n",
            "Epoch 143/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 140.6811 - val_loss: 170.6556\n",
            "Epoch 144/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.5530 - val_loss: 153.9337\n",
            "Epoch 145/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.7036 - val_loss: 162.0473\n",
            "Epoch 146/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 135.0691 - val_loss: 156.2039\n",
            "Epoch 147/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.1340 - val_loss: 155.8650\n",
            "Epoch 148/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.0875 - val_loss: 176.3640\n",
            "Epoch 149/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 141.9821 - val_loss: 163.9506\n",
            "Epoch 150/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 139.2045 - val_loss: 157.1489\n",
            "Epoch 151/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.1884 - val_loss: 158.9709\n",
            "Epoch 152/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.1770 - val_loss: 153.2452\n",
            "Epoch 153/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.1569 - val_loss: 156.9487\n",
            "Epoch 154/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.8831 - val_loss: 154.6164\n",
            "Epoch 155/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.7368 - val_loss: 153.3816\n",
            "Epoch 156/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 142.5247 - val_loss: 165.2215\n",
            "Epoch 157/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.7947 - val_loss: 173.4253\n",
            "Epoch 158/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.4424 - val_loss: 160.6960\n",
            "Epoch 159/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.8447 - val_loss: 182.9953\n",
            "Epoch 160/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.2608 - val_loss: 175.6265\n",
            "Epoch 161/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 144.3377 - val_loss: 184.8435\n",
            "Epoch 162/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 139.1346 - val_loss: 158.0078\n",
            "Epoch 163/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.8976 - val_loss: 156.5055\n",
            "Epoch 164/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 141.6369 - val_loss: 154.7197\n",
            "Epoch 165/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 139.1090 - val_loss: 163.7806\n",
            "Epoch 166/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 138.7822 - val_loss: 176.1800\n",
            "Epoch 167/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.2905 - val_loss: 169.1734\n",
            "Epoch 168/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 138.8203 - val_loss: 173.9109\n",
            "Epoch 169/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.8625 - val_loss: 155.7861\n",
            "Epoch 170/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 140.8481 - val_loss: 164.3226\n",
            "Epoch 171/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.8030 - val_loss: 170.8396\n",
            "Epoch 172/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.5865 - val_loss: 156.3863\n",
            "Epoch 173/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.9252 - val_loss: 187.6755\n",
            "Epoch 174/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 141.8529 - val_loss: 166.0806\n",
            "Epoch 175/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.3723 - val_loss: 160.5563\n",
            "Epoch 176/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.3926 - val_loss: 158.7989\n",
            "Epoch 177/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.6176 - val_loss: 161.2802\n",
            "Epoch 178/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.7671 - val_loss: 156.9452\n",
            "Epoch 179/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.2879 - val_loss: 179.9382\n",
            "Epoch 180/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 141.7054 - val_loss: 181.4627\n",
            "Epoch 181/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 138.3145 - val_loss: 156.1716\n",
            "Epoch 182/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.0782 - val_loss: 158.6172\n",
            "Epoch 183/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.0235 - val_loss: 180.6026\n",
            "Epoch 184/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.2837 - val_loss: 160.6851\n",
            "Epoch 185/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 139.7977 - val_loss: 157.0153\n",
            "Epoch 186/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 143.0095 - val_loss: 172.2033\n",
            "Epoch 187/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.1093 - val_loss: 177.1484\n",
            "Epoch 188/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 143.1937 - val_loss: 165.8213\n",
            "Epoch 189/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.5972 - val_loss: 181.6624\n",
            "Epoch 190/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 138.8017 - val_loss: 185.8963\n",
            "Epoch 191/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.8931 - val_loss: 157.5712\n",
            "Epoch 192/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 136.7486 - val_loss: 156.5177\n",
            "Epoch 193/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.6661 - val_loss: 164.9436\n",
            "Epoch 194/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.2436 - val_loss: 160.5288\n",
            "Epoch 195/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 135.5443 - val_loss: 157.6671\n",
            "Epoch 196/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.5732 - val_loss: 160.9285\n",
            "Epoch 197/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.5167 - val_loss: 178.3866\n",
            "Epoch 198/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 152.8743 - val_loss: 160.3260\n",
            "Epoch 199/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 147.1759 - val_loss: 153.7537\n",
            "Epoch 200/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.9734 - val_loss: 157.0579\n",
            "Epoch 201/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.3970 - val_loss: 160.6677\n",
            "Epoch 202/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.6667 - val_loss: 162.1077\n",
            "Epoch 203/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.4731 - val_loss: 154.9041\n",
            "Epoch 204/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.8365 - val_loss: 174.5514\n",
            "Epoch 205/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 139.5870 - val_loss: 163.5491\n",
            "Epoch 206/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.0679 - val_loss: 159.3561\n",
            "Epoch 207/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.2697 - val_loss: 156.2435\n",
            "Epoch 208/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.4396 - val_loss: 161.3812\n",
            "Epoch 209/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.7666 - val_loss: 168.9557\n",
            "Epoch 210/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.3021 - val_loss: 167.2495\n",
            "Epoch 211/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.6065 - val_loss: 163.6500\n",
            "Epoch 212/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.7742 - val_loss: 167.7630\n",
            "Epoch 213/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.8118 - val_loss: 155.5830\n",
            "Epoch 214/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 139.0381 - val_loss: 192.9392\n",
            "Epoch 215/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 145.8477 - val_loss: 165.7613\n",
            "Epoch 216/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 139.8053 - val_loss: 159.8884\n",
            "Epoch 217/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.7891 - val_loss: 155.2561\n",
            "Epoch 218/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.3551 - val_loss: 166.5992\n",
            "Epoch 219/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.5934 - val_loss: 158.9173\n",
            "Epoch 220/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.6862 - val_loss: 172.6378\n",
            "Epoch 221/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 143.5189 - val_loss: 159.0214\n",
            "Epoch 222/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.0123 - val_loss: 157.1039\n",
            "Epoch 223/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.3312 - val_loss: 160.4441\n",
            "Epoch 224/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.1584 - val_loss: 155.3376\n",
            "Epoch 225/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.3994 - val_loss: 160.8580\n",
            "Epoch 226/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.3477 - val_loss: 156.0189\n",
            "Epoch 227/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 139.5142 - val_loss: 166.6616\n",
            "Epoch 228/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.5984 - val_loss: 181.2279\n",
            "Epoch 229/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.5167 - val_loss: 158.7488\n",
            "Epoch 230/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.4723 - val_loss: 182.3569\n",
            "Epoch 231/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.2980 - val_loss: 171.5366\n",
            "Epoch 232/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.2210 - val_loss: 159.6859\n",
            "Epoch 233/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.5812 - val_loss: 159.7481\n",
            "Epoch 234/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.6799 - val_loss: 159.5590\n",
            "Epoch 235/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.0906 - val_loss: 153.9563\n",
            "Epoch 236/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 140.8356 - val_loss: 166.9539\n",
            "Epoch 237/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.7946 - val_loss: 159.7744\n",
            "Epoch 238/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 133.5500 - val_loss: 183.0301\n",
            "Epoch 239/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.7341 - val_loss: 173.7341\n",
            "Epoch 240/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 143.9010 - val_loss: 200.3345\n",
            "Epoch 241/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 141.2785 - val_loss: 152.7964\n",
            "Epoch 242/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 141.6731 - val_loss: 162.3293\n",
            "Epoch 243/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 135.8733 - val_loss: 162.4992\n",
            "Epoch 244/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 138.6599 - val_loss: 170.6267\n",
            "Epoch 245/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 140.2074 - val_loss: 166.8574\n",
            "Epoch 246/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 140.1269 - val_loss: 162.0289\n",
            "Epoch 247/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 146.0531 - val_loss: 156.9310\n",
            "Epoch 248/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 138.3130 - val_loss: 155.8494\n",
            "Epoch 249/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.5494 - val_loss: 155.7552\n",
            "Epoch 250/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.6320 - val_loss: 158.9158\n",
            "Epoch 251/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 138.7923 - val_loss: 154.7120\n",
            "Epoch 252/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 141.1279 - val_loss: 165.3446\n",
            "Epoch 253/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.9167 - val_loss: 153.2838\n",
            "Epoch 254/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 141.7346 - val_loss: 163.1315\n",
            "Epoch 255/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.9404 - val_loss: 171.3606\n",
            "Epoch 256/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 138.5933 - val_loss: 153.8710\n",
            "Epoch 257/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 139.0719 - val_loss: 156.3318\n",
            "Epoch 258/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.5481 - val_loss: 157.4557\n",
            "Epoch 259/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.1519 - val_loss: 161.4444\n",
            "Epoch 260/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.9601 - val_loss: 153.8529\n",
            "Epoch 261/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 139.2549 - val_loss: 155.1863\n",
            "Epoch 262/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.2503 - val_loss: 160.9485\n",
            "Epoch 263/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.6266 - val_loss: 157.5782\n",
            "Epoch 264/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 136.5461 - val_loss: 162.9044\n",
            "Epoch 265/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 140.9659 - val_loss: 157.8007\n",
            "Epoch 266/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 138.3405 - val_loss: 166.3005\n",
            "Epoch 267/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.1789 - val_loss: 158.9355\n",
            "Epoch 268/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 134.7766 - val_loss: 162.8001\n",
            "Epoch 269/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.5629 - val_loss: 178.5424\n",
            "Epoch 270/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.7299 - val_loss: 168.7833\n",
            "Epoch 271/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.0401 - val_loss: 178.9254\n",
            "Epoch 272/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 136.2310 - val_loss: 169.7185\n",
            "Epoch 273/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.7783 - val_loss: 157.4004\n",
            "Epoch 274/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.5768 - val_loss: 160.7599\n",
            "Epoch 275/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.1868 - val_loss: 159.6413\n",
            "Epoch 276/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.3467 - val_loss: 166.5092\n",
            "Epoch 277/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 135.1957 - val_loss: 172.3138\n",
            "Epoch 278/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.2753 - val_loss: 164.0479\n",
            "Epoch 279/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 136.8555 - val_loss: 155.6240\n",
            "Epoch 280/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 140.3506 - val_loss: 156.2898\n",
            "Epoch 281/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.1839 - val_loss: 171.5686\n",
            "Epoch 282/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.3591 - val_loss: 159.6838\n",
            "Epoch 283/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 134.9274 - val_loss: 175.3204\n",
            "Epoch 284/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 138.9024 - val_loss: 170.2214\n",
            "Epoch 285/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.8342 - val_loss: 164.7374\n",
            "Epoch 286/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 138.5315 - val_loss: 163.8761\n",
            "Epoch 287/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.5493 - val_loss: 157.4593\n",
            "Epoch 288/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.1200 - val_loss: 163.1385\n",
            "Epoch 289/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.6933 - val_loss: 160.0829\n",
            "Epoch 290/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 138.6513 - val_loss: 175.6880\n",
            "Epoch 291/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.1016 - val_loss: 154.5165\n",
            "Epoch 292/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 141.2385 - val_loss: 170.1159\n",
            "Epoch 293/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.1883 - val_loss: 159.3569\n",
            "Epoch 294/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.6192 - val_loss: 157.5343\n",
            "Epoch 295/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.5463 - val_loss: 185.2065\n",
            "Epoch 296/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.3699 - val_loss: 157.9537\n",
            "Epoch 297/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.1958 - val_loss: 163.2781\n",
            "Epoch 298/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.6653 - val_loss: 158.6949\n",
            "Epoch 299/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.8640 - val_loss: 161.3411\n",
            "Epoch 300/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.4811 - val_loss: 161.4557\n",
            "Epoch 301/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 135.5122 - val_loss: 170.6760\n",
            "Epoch 302/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 139.8035 - val_loss: 154.9266\n",
            "Epoch 303/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.2213 - val_loss: 169.7310\n",
            "Epoch 304/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.2229 - val_loss: 161.4245\n",
            "Epoch 305/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 140.4998 - val_loss: 167.4203\n",
            "Epoch 306/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 144.2144 - val_loss: 158.8714\n",
            "Epoch 307/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.7586 - val_loss: 157.9912\n",
            "Epoch 308/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.4828 - val_loss: 158.5625\n",
            "Epoch 309/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.4995 - val_loss: 166.9624\n",
            "Epoch 310/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.5164 - val_loss: 159.5424\n",
            "Epoch 311/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 135.1529 - val_loss: 156.9918\n",
            "Epoch 312/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.5461 - val_loss: 154.2791\n",
            "Epoch 313/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.7582 - val_loss: 153.7173\n",
            "Epoch 314/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.5325 - val_loss: 157.7861\n",
            "Epoch 315/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.1097 - val_loss: 163.3160\n",
            "Epoch 316/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.8043 - val_loss: 168.4935\n",
            "Epoch 317/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.8997 - val_loss: 184.1881\n",
            "Epoch 318/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 146.2437 - val_loss: 173.1513\n",
            "Epoch 319/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 155.0818 - val_loss: 171.6543\n",
            "Epoch 320/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 138.2746 - val_loss: 156.8728\n",
            "Epoch 321/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.0223 - val_loss: 163.4066\n",
            "Epoch 322/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.6008 - val_loss: 169.0769\n",
            "Epoch 323/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 139.2538 - val_loss: 170.7603\n",
            "Epoch 324/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 140.3827 - val_loss: 158.7581\n",
            "Epoch 325/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 140.1018 - val_loss: 157.1395\n",
            "Epoch 326/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 135.0187 - val_loss: 156.9102\n",
            "Epoch 327/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.8839 - val_loss: 178.3384\n",
            "Epoch 328/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.6575 - val_loss: 165.0401\n",
            "Epoch 329/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.5670 - val_loss: 161.4997\n",
            "Epoch 330/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.9469 - val_loss: 160.8979\n",
            "Epoch 331/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.8770 - val_loss: 156.9727\n",
            "Epoch 332/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 136.6841 - val_loss: 163.8365\n",
            "Epoch 333/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.0920 - val_loss: 165.0916\n",
            "Epoch 334/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.6989 - val_loss: 154.8680\n",
            "Epoch 335/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 138.7533 - val_loss: 162.5444\n",
            "Epoch 336/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.8558 - val_loss: 187.6584\n",
            "Epoch 337/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.3378 - val_loss: 160.1043\n",
            "Epoch 338/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.6800 - val_loss: 157.3620\n",
            "Epoch 339/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.9232 - val_loss: 155.8840\n",
            "Epoch 340/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 135.0110 - val_loss: 161.1721\n",
            "Epoch 341/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.1420 - val_loss: 166.3989\n",
            "Epoch 342/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.3663 - val_loss: 155.8465\n",
            "Epoch 343/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.5301 - val_loss: 159.8571\n",
            "Epoch 344/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.6506 - val_loss: 172.1502\n",
            "Epoch 345/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.4875 - val_loss: 159.5775\n",
            "Epoch 346/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 135.2489 - val_loss: 162.5130\n",
            "Epoch 347/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 139.4336 - val_loss: 171.6890\n",
            "Epoch 348/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.2599 - val_loss: 176.7134\n",
            "Epoch 349/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 138.9293 - val_loss: 157.5393\n",
            "Epoch 350/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 145.7089 - val_loss: 168.8546\n",
            "Epoch 351/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.0266 - val_loss: 167.0938\n",
            "Epoch 352/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.2854 - val_loss: 178.4825\n",
            "Epoch 353/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 138.8826 - val_loss: 164.8711\n",
            "Epoch 354/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 137.7217 - val_loss: 156.6284\n",
            "Epoch 355/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.2460 - val_loss: 157.5269\n",
            "Epoch 356/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.4492 - val_loss: 168.9611\n",
            "Epoch 357/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.1020 - val_loss: 159.0033\n",
            "Epoch 358/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.8323 - val_loss: 160.2709\n",
            "Epoch 359/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.4787 - val_loss: 159.2067\n",
            "Epoch 360/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.1895 - val_loss: 158.7194\n",
            "Epoch 361/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 138.4185 - val_loss: 163.5550\n",
            "Epoch 362/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.8214 - val_loss: 153.2911\n",
            "Epoch 363/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 142.0679 - val_loss: 157.5413\n",
            "Epoch 364/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 140.7011 - val_loss: 162.9597\n",
            "Epoch 365/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 141.3969 - val_loss: 175.0040\n",
            "Epoch 366/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.9250 - val_loss: 190.7977\n",
            "Epoch 367/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 140.9094 - val_loss: 159.2819\n",
            "Epoch 368/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 135.1155 - val_loss: 155.0885\n",
            "Epoch 369/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 140.4949 - val_loss: 156.7961\n",
            "Epoch 370/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.5358 - val_loss: 194.4246\n",
            "Epoch 371/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 144.1140 - val_loss: 193.4883\n",
            "Epoch 372/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 143.2894 - val_loss: 161.9161\n",
            "Epoch 373/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.3896 - val_loss: 155.7882\n",
            "Epoch 374/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 143.1000 - val_loss: 191.5413\n",
            "Epoch 375/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 140.6998 - val_loss: 173.7276\n",
            "Epoch 376/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.0828 - val_loss: 165.8013\n",
            "Epoch 377/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.9339 - val_loss: 167.0311\n",
            "Epoch 378/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 139.1098 - val_loss: 156.7652\n",
            "Epoch 379/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.4107 - val_loss: 155.8340\n",
            "Epoch 380/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.8889 - val_loss: 161.1654\n",
            "Epoch 381/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.8738 - val_loss: 172.9413\n",
            "Epoch 382/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 136.4044 - val_loss: 154.4062\n",
            "Epoch 383/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.9907 - val_loss: 158.0967\n",
            "Epoch 384/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.9158 - val_loss: 152.5659\n",
            "Epoch 385/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 140.2824 - val_loss: 153.2735\n",
            "Epoch 386/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 138.5275 - val_loss: 153.9763\n",
            "Epoch 387/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 142.1230 - val_loss: 162.3607\n",
            "Epoch 388/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.7575 - val_loss: 172.8719\n",
            "Epoch 389/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.7083 - val_loss: 154.0268\n",
            "Epoch 390/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.4174 - val_loss: 164.6139\n",
            "Epoch 391/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.8806 - val_loss: 161.7980\n",
            "Epoch 392/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.8642 - val_loss: 162.9251\n",
            "Epoch 393/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 138.4164 - val_loss: 169.4295\n",
            "Epoch 394/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 139.2342 - val_loss: 165.6740\n",
            "Epoch 395/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.1642 - val_loss: 159.0227\n",
            "Epoch 396/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.4553 - val_loss: 159.2880\n",
            "Epoch 397/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 138.3829 - val_loss: 161.4891\n",
            "Epoch 398/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 145.6841 - val_loss: 165.6860\n",
            "Epoch 399/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.9570 - val_loss: 157.2776\n",
            "Epoch 400/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.3058 - val_loss: 162.1780\n",
            "Epoch 401/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.9239 - val_loss: 158.6512\n",
            "Epoch 402/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.1718 - val_loss: 154.6988\n",
            "Epoch 403/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 134.6735 - val_loss: 158.6506\n",
            "Epoch 404/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.1949 - val_loss: 155.9907\n",
            "Epoch 405/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.9621 - val_loss: 176.8390\n",
            "Epoch 406/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 140.0542 - val_loss: 176.3738\n",
            "Epoch 407/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 143.0757 - val_loss: 154.4310\n",
            "Epoch 408/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.7092 - val_loss: 157.0671\n",
            "Epoch 409/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.7474 - val_loss: 160.2326\n",
            "Epoch 410/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.2307 - val_loss: 165.7122\n",
            "Epoch 411/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.9627 - val_loss: 179.7698\n",
            "Epoch 412/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.4066 - val_loss: 156.1579\n",
            "Epoch 413/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.7323 - val_loss: 155.8083\n",
            "Epoch 414/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 138.4273 - val_loss: 166.7825\n",
            "Epoch 415/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.0421 - val_loss: 162.5035\n",
            "Epoch 416/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.8815 - val_loss: 165.0256\n",
            "Epoch 417/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.0872 - val_loss: 157.5847\n",
            "Epoch 418/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.2698 - val_loss: 158.7460\n",
            "Epoch 419/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.0969 - val_loss: 157.8752\n",
            "Epoch 420/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 138.3381 - val_loss: 154.1790\n",
            "Epoch 421/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 142.4402 - val_loss: 158.6754\n",
            "Epoch 422/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 135.6573 - val_loss: 161.9374\n",
            "Epoch 423/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 135.3658 - val_loss: 157.1815\n",
            "Epoch 424/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.2897 - val_loss: 170.8671\n",
            "Epoch 425/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.6850 - val_loss: 159.4689\n",
            "Epoch 426/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.7050 - val_loss: 164.9326\n",
            "Epoch 427/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.7126 - val_loss: 156.2234\n",
            "Epoch 428/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.3261 - val_loss: 154.0650\n",
            "Epoch 429/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 145.2124 - val_loss: 159.6929\n",
            "Epoch 430/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.9592 - val_loss: 160.8345\n",
            "Epoch 431/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.6700 - val_loss: 154.9346\n",
            "Epoch 432/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.3711 - val_loss: 155.6381\n",
            "Epoch 433/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.3203 - val_loss: 152.0629\n",
            "Epoch 434/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 141.6429 - val_loss: 151.9388\n",
            "Epoch 435/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 142.4777 - val_loss: 172.7429\n",
            "Epoch 436/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.5861 - val_loss: 175.2787\n",
            "Epoch 437/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.7829 - val_loss: 165.8025\n",
            "Epoch 438/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.9181 - val_loss: 158.3827\n",
            "Epoch 439/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 140.1723 - val_loss: 159.7886\n",
            "Epoch 440/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.9469 - val_loss: 168.0799\n",
            "Epoch 441/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 138.6981 - val_loss: 165.4486\n",
            "Epoch 442/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 139.6649 - val_loss: 160.1082\n",
            "Epoch 443/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.4922 - val_loss: 155.3869\n",
            "Epoch 444/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 135.5972 - val_loss: 152.5645\n",
            "Epoch 445/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.3096 - val_loss: 180.5986\n",
            "Epoch 446/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.7574 - val_loss: 183.7147\n",
            "Epoch 447/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 140.2204 - val_loss: 203.8513\n",
            "Epoch 448/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 153.3654 - val_loss: 156.7197\n",
            "Epoch 449/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.9606 - val_loss: 167.0012\n",
            "Epoch 450/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.6740 - val_loss: 154.2339\n",
            "Epoch 451/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.9326 - val_loss: 175.1098\n",
            "Epoch 452/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.8407 - val_loss: 176.1696\n",
            "Epoch 453/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 144.7190 - val_loss: 154.2889\n",
            "Epoch 454/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.6028 - val_loss: 154.7116\n",
            "Epoch 455/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.1264 - val_loss: 154.0843\n",
            "Epoch 456/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.5154 - val_loss: 161.3856\n",
            "Epoch 457/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.1681 - val_loss: 162.0172\n",
            "Epoch 458/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.6944 - val_loss: 164.4396\n",
            "Epoch 459/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.3364 - val_loss: 157.9472\n",
            "Epoch 460/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 136.1837 - val_loss: 173.5565\n",
            "Epoch 461/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.6707 - val_loss: 164.3171\n",
            "Epoch 462/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.3856 - val_loss: 157.5822\n",
            "Epoch 463/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.3918 - val_loss: 175.9883\n",
            "Epoch 464/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 142.0499 - val_loss: 152.5572\n",
            "Epoch 465/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.8565 - val_loss: 157.6030\n",
            "Epoch 466/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 134.8061 - val_loss: 153.4210\n",
            "Epoch 467/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 157.3723 - val_loss: 162.2781\n",
            "Epoch 468/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.9755 - val_loss: 156.7599\n",
            "Epoch 469/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.2303 - val_loss: 166.3702\n",
            "Epoch 470/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.6475 - val_loss: 156.6650\n",
            "Epoch 471/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.4190 - val_loss: 154.0944\n",
            "Epoch 472/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 146.3342 - val_loss: 160.7771\n",
            "Epoch 473/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 140.1788 - val_loss: 176.0569\n",
            "Epoch 474/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.3293 - val_loss: 170.3953\n",
            "Epoch 475/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.0110 - val_loss: 160.2702\n",
            "Epoch 476/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.4025 - val_loss: 154.3788\n",
            "Epoch 477/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 141.0640 - val_loss: 173.2282\n",
            "Epoch 478/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.1792 - val_loss: 166.1070\n",
            "Epoch 479/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.9734 - val_loss: 163.1552\n",
            "Epoch 480/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 135.8107 - val_loss: 153.9387\n",
            "Epoch 481/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.6473 - val_loss: 162.6868\n",
            "Epoch 482/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.0317 - val_loss: 174.9166\n",
            "Epoch 483/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 138.5401 - val_loss: 181.0382\n",
            "Epoch 484/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.9240 - val_loss: 161.3856\n",
            "Epoch 485/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 138.0802 - val_loss: 162.1287\n",
            "Epoch 486/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.4551 - val_loss: 161.7101\n",
            "Epoch 487/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.1505 - val_loss: 160.8892\n",
            "Epoch 488/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 136.2874 - val_loss: 155.5573\n",
            "Epoch 489/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 138.6261 - val_loss: 163.4430\n",
            "Epoch 490/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 142.0095 - val_loss: 154.1106\n",
            "Epoch 491/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.1313 - val_loss: 157.6629\n",
            "Epoch 492/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.0280 - val_loss: 166.5549\n",
            "Epoch 493/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.1608 - val_loss: 173.1978\n",
            "Epoch 494/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 142.4208 - val_loss: 168.9646\n",
            "Epoch 495/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 143.8094 - val_loss: 162.2010\n",
            "Epoch 496/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 138.9840 - val_loss: 160.5109\n",
            "Epoch 497/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 135.7195 - val_loss: 164.7370\n",
            "Epoch 498/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.4005 - val_loss: 156.6399\n",
            "Epoch 499/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 134.4913 - val_loss: 159.1515\n",
            "Epoch 500/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 137.2296 - val_loss: 155.3583\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faf05d90710>"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ],
      "source": [
        "model.fit(x, t, validation_split=0.1, shuffle=True, batch_size=64, epochs=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iK7qGVmxu3WR"
      },
      "outputs": [],
      "source": [
        "\n",
        "hs_gpa = np.linspace(1, 6, 50)\n",
        "fy_gpa = np.linspace(1, 6, 50)\n",
        "zeros = np.zeros(50)\n",
        "ones = np.ones(50)\n",
        "\n",
        "sex_1 = np.stack([hs_gpa, zeros, zeros]).T\n",
        "sex_2 = np.stack([hs_gpa, zeros, ones]).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "pe8708VLvpTb",
        "outputId": "1dcb8ee0-1c92-465a-b881-748da97002b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7faf05bd0c50>]"
            ]
          },
          "metadata": {},
          "execution_count": 152
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "\n",
        "\n",
        "plt.plot(hs_gpa, model(sex_1)[:, 0])\n",
        "plt.plot(hs_gpa, model(sex_2)[:, 0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.corrcoef(model(x)[:, 0].numpy(), t_m[:, 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZ6zVewkZNrh",
        "outputId": "2d00496d-4b8c-4269-a024-4adc32ad21db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.        , -0.30631983],\n",
              "       [-0.30631983,  1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9P969XcWqku8"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "                              tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "                              tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "                              tf.keras.layers.Dense(32, activation=\"relu\"),\n",
        "                              tf.keras.layers.Dense(8, activation=\"relu\"),\n",
        "                             tf.keras.layers.Dense(1, activation=None),\n",
        "                              ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8Uz0w1jqku9"
      },
      "outputs": [],
      "source": [
        "def loss_func(y_true, y_pred):\n",
        "  return tf.keras.losses.mean_squared_error(y_true[:, :1], y_pred) * (tf.math.abs(tfp.stats.covariance(y_true[:, 1:], y_pred)) + 1)  # / tf.keras.losses.kullback_leibler_divergence(y_true[:, 1:], y_pred) \n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "              loss = loss_func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRoQA8Whqku-",
        "outputId": "f22cf43f-306c-4006-f67f-da55009c43a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "15/15 [==============================] - 1s 16ms/step - loss: 10837.6406 - val_loss: 11406.1348\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 10794.7871 - val_loss: 11331.5840\n",
            "Epoch 3/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 10784.0020 - val_loss: 11320.9473\n",
            "Epoch 4/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 10757.8789 - val_loss: 11315.5850\n",
            "Epoch 5/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 10726.4814 - val_loss: 11270.7559\n",
            "Epoch 6/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 10700.4951 - val_loss: 11177.1787\n",
            "Epoch 7/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 10610.2920 - val_loss: 11078.0000\n",
            "Epoch 8/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 10551.4766 - val_loss: 10975.3027\n",
            "Epoch 9/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 10355.4453 - val_loss: 10810.8760\n",
            "Epoch 10/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 10144.5234 - val_loss: 10493.4785\n",
            "Epoch 11/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 9933.2393 - val_loss: 9910.1201\n",
            "Epoch 12/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 9019.8037 - val_loss: 8666.7900\n",
            "Epoch 13/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 7870.7021 - val_loss: 6333.5952\n",
            "Epoch 14/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4060.4072 - val_loss: 1761.1620\n",
            "Epoch 15/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 802.4813 - val_loss: 585.6274\n",
            "Epoch 16/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 541.8870 - val_loss: 592.4484\n",
            "Epoch 17/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 423.2126 - val_loss: 412.7246\n",
            "Epoch 18/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 480.4416 - val_loss: 390.8934\n",
            "Epoch 19/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 415.5421 - val_loss: 400.0681\n",
            "Epoch 20/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 456.5393 - val_loss: 382.4771\n",
            "Epoch 21/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 422.8455 - val_loss: 375.6243\n",
            "Epoch 22/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 414.2444 - val_loss: 371.0710\n",
            "Epoch 23/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 377.2668 - val_loss: 408.5702\n",
            "Epoch 24/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 377.6628 - val_loss: 341.7533\n",
            "Epoch 25/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 379.7101 - val_loss: 343.4336\n",
            "Epoch 26/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 312.6581 - val_loss: 320.0711\n",
            "Epoch 27/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 406.1789 - val_loss: 328.4165\n",
            "Epoch 28/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 315.4258 - val_loss: 333.4552\n",
            "Epoch 29/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 384.5766 - val_loss: 335.3714\n",
            "Epoch 30/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 360.6401 - val_loss: 345.9356\n",
            "Epoch 31/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 322.8312 - val_loss: 333.6329\n",
            "Epoch 32/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 339.5325 - val_loss: 319.7725\n",
            "Epoch 33/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 382.8237 - val_loss: 319.6232\n",
            "Epoch 34/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 302.5062 - val_loss: 311.8376\n",
            "Epoch 35/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 274.6754 - val_loss: 318.4150\n",
            "Epoch 36/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 334.8912 - val_loss: 319.4279\n",
            "Epoch 37/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 312.3346 - val_loss: 303.3107\n",
            "Epoch 38/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 349.6194 - val_loss: 306.1625\n",
            "Epoch 39/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 348.8304 - val_loss: 308.0982\n",
            "Epoch 40/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 331.1976 - val_loss: 298.1056\n",
            "Epoch 41/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 308.6089 - val_loss: 303.5468\n",
            "Epoch 42/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 318.0581 - val_loss: 314.8983\n",
            "Epoch 43/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 314.8499 - val_loss: 295.7341\n",
            "Epoch 44/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 296.3799 - val_loss: 293.3843\n",
            "Epoch 45/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 341.3163 - val_loss: 319.6221\n",
            "Epoch 46/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 310.7415 - val_loss: 314.8339\n",
            "Epoch 47/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 307.7149 - val_loss: 280.3143\n",
            "Epoch 48/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 312.5675 - val_loss: 305.9786\n",
            "Epoch 49/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 313.3025 - val_loss: 292.0529\n",
            "Epoch 50/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 265.2239 - val_loss: 275.7640\n",
            "Epoch 51/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 289.7612 - val_loss: 270.6812\n",
            "Epoch 52/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 240.0014 - val_loss: 277.4805\n",
            "Epoch 53/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 261.6192 - val_loss: 284.2831\n",
            "Epoch 54/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 294.7672 - val_loss: 264.7809\n",
            "Epoch 55/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 285.4993 - val_loss: 281.7682\n",
            "Epoch 56/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 304.9704 - val_loss: 281.7994\n",
            "Epoch 57/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 269.7130 - val_loss: 269.4002\n",
            "Epoch 58/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 288.0858 - val_loss: 256.8272\n",
            "Epoch 59/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 277.8796 - val_loss: 278.8772\n",
            "Epoch 60/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 297.5203 - val_loss: 260.8966\n",
            "Epoch 61/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 248.9708 - val_loss: 259.0615\n",
            "Epoch 62/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 255.4936 - val_loss: 268.2490\n",
            "Epoch 63/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 261.9223 - val_loss: 254.8763\n",
            "Epoch 64/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 248.4930 - val_loss: 247.6757\n",
            "Epoch 65/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 261.9310 - val_loss: 272.8443\n",
            "Epoch 66/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 266.3142 - val_loss: 244.7906\n",
            "Epoch 67/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 223.9964 - val_loss: 261.5453\n",
            "Epoch 68/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 213.5431 - val_loss: 254.8420\n",
            "Epoch 69/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 224.1506 - val_loss: 244.8168\n",
            "Epoch 70/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 235.5307 - val_loss: 250.6461\n",
            "Epoch 71/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 227.7291 - val_loss: 243.4813\n",
            "Epoch 72/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 215.2236 - val_loss: 260.9281\n",
            "Epoch 73/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 235.3431 - val_loss: 232.4862\n",
            "Epoch 74/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 225.2858 - val_loss: 253.7517\n",
            "Epoch 75/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 225.1915 - val_loss: 225.8021\n",
            "Epoch 76/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 197.4889 - val_loss: 242.1637\n",
            "Epoch 77/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 198.4838 - val_loss: 231.9435\n",
            "Epoch 78/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 249.4911 - val_loss: 233.7358\n",
            "Epoch 79/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 205.0278 - val_loss: 229.4282\n",
            "Epoch 80/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 208.0623 - val_loss: 222.1348\n",
            "Epoch 81/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 242.5621 - val_loss: 245.9597\n",
            "Epoch 82/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 216.6053 - val_loss: 253.2144\n",
            "Epoch 83/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 215.2840 - val_loss: 219.9552\n",
            "Epoch 84/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 192.7899 - val_loss: 222.9420\n",
            "Epoch 85/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 238.6213 - val_loss: 251.9309\n",
            "Epoch 86/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 221.9754 - val_loss: 230.5045\n",
            "Epoch 87/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 206.1617 - val_loss: 233.2211\n",
            "Epoch 88/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 189.0481 - val_loss: 220.4086\n",
            "Epoch 89/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 199.0599 - val_loss: 226.8396\n",
            "Epoch 90/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 200.7443 - val_loss: 226.9853\n",
            "Epoch 91/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 232.3278 - val_loss: 233.4890\n",
            "Epoch 92/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 236.9332 - val_loss: 217.5966\n",
            "Epoch 93/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 224.7198 - val_loss: 254.2137\n",
            "Epoch 94/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 199.4986 - val_loss: 222.6745\n",
            "Epoch 95/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 192.6865 - val_loss: 221.0587\n",
            "Epoch 96/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 216.8921 - val_loss: 218.7052\n",
            "Epoch 97/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 196.7900 - val_loss: 236.5240\n",
            "Epoch 98/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 185.0847 - val_loss: 218.3723\n",
            "Epoch 99/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 196.2818 - val_loss: 232.0154\n",
            "Epoch 100/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 193.4745 - val_loss: 233.5277\n",
            "Epoch 101/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 199.5462 - val_loss: 219.2271\n",
            "Epoch 102/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 189.4285 - val_loss: 219.4601\n",
            "Epoch 103/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 179.4074 - val_loss: 248.6608\n",
            "Epoch 104/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 192.4438 - val_loss: 212.3256\n",
            "Epoch 105/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 181.6404 - val_loss: 209.4816\n",
            "Epoch 106/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 220.2882 - val_loss: 276.0739\n",
            "Epoch 107/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 199.1202 - val_loss: 222.6102\n",
            "Epoch 108/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 205.4543 - val_loss: 227.0797\n",
            "Epoch 109/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 198.6386 - val_loss: 225.3098\n",
            "Epoch 110/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 188.2130 - val_loss: 225.7842\n",
            "Epoch 111/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 201.6929 - val_loss: 233.9303\n",
            "Epoch 112/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 191.4462 - val_loss: 235.1856\n",
            "Epoch 113/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 201.4287 - val_loss: 214.3254\n",
            "Epoch 114/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 218.6397 - val_loss: 254.7233\n",
            "Epoch 115/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 193.2007 - val_loss: 226.5108\n",
            "Epoch 116/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 187.7615 - val_loss: 223.1664\n",
            "Epoch 117/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 199.8255 - val_loss: 230.6040\n",
            "Epoch 118/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 190.4773 - val_loss: 234.7335\n",
            "Epoch 119/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 206.0891 - val_loss: 221.6042\n",
            "Epoch 120/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 195.7776 - val_loss: 227.8588\n",
            "Epoch 121/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 202.0594 - val_loss: 234.7540\n",
            "Epoch 122/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 200.3694 - val_loss: 220.1482\n",
            "Epoch 123/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 188.1409 - val_loss: 235.6343\n",
            "Epoch 124/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 195.9119 - val_loss: 209.9036\n",
            "Epoch 125/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 183.1148 - val_loss: 231.9951\n",
            "Epoch 126/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 190.4734 - val_loss: 216.0209\n",
            "Epoch 127/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 190.9020 - val_loss: 233.1393\n",
            "Epoch 128/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 200.1700 - val_loss: 224.6804\n",
            "Epoch 129/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 200.6327 - val_loss: 212.6636\n",
            "Epoch 130/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 197.2239 - val_loss: 216.1937\n",
            "Epoch 131/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 183.2439 - val_loss: 221.5691\n",
            "Epoch 132/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 192.9171 - val_loss: 212.6733\n",
            "Epoch 133/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 196.7847 - val_loss: 223.7118\n",
            "Epoch 134/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 186.8805 - val_loss: 228.7557\n",
            "Epoch 135/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 204.3784 - val_loss: 222.8993\n",
            "Epoch 136/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 209.4670 - val_loss: 264.2471\n",
            "Epoch 137/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 191.2301 - val_loss: 212.7480\n",
            "Epoch 138/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 179.3149 - val_loss: 215.4055\n",
            "Epoch 139/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 194.8208 - val_loss: 243.8417\n",
            "Epoch 140/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 188.9015 - val_loss: 214.9637\n",
            "Epoch 141/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 181.0800 - val_loss: 213.9158\n",
            "Epoch 142/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 186.7345 - val_loss: 242.4880\n",
            "Epoch 143/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 176.1799 - val_loss: 208.9644\n",
            "Epoch 144/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 197.2915 - val_loss: 220.5658\n",
            "Epoch 145/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 193.3393 - val_loss: 225.5726\n",
            "Epoch 146/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 182.1656 - val_loss: 233.1120\n",
            "Epoch 147/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 187.2742 - val_loss: 215.1613\n",
            "Epoch 148/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 205.3793 - val_loss: 238.0757\n",
            "Epoch 149/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 177.5756 - val_loss: 217.2038\n",
            "Epoch 150/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 170.5180 - val_loss: 229.0983\n",
            "Epoch 151/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 196.4146 - val_loss: 209.1423\n",
            "Epoch 152/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 196.8589 - val_loss: 228.1193\n",
            "Epoch 153/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 204.8866 - val_loss: 214.4569\n",
            "Epoch 154/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 207.8019 - val_loss: 217.7591\n",
            "Epoch 155/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 187.0225 - val_loss: 234.1069\n",
            "Epoch 156/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 191.6587 - val_loss: 227.5945\n",
            "Epoch 157/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 185.8501 - val_loss: 215.3555\n",
            "Epoch 158/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 188.0426 - val_loss: 226.1351\n",
            "Epoch 159/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 191.2140 - val_loss: 244.3906\n",
            "Epoch 160/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 192.8425 - val_loss: 233.8969\n",
            "Epoch 161/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 206.4693 - val_loss: 207.5143\n",
            "Epoch 162/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 187.1125 - val_loss: 226.1763\n",
            "Epoch 163/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 196.3224 - val_loss: 211.5988\n",
            "Epoch 164/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 192.3652 - val_loss: 215.8074\n",
            "Epoch 165/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 185.7023 - val_loss: 223.5659\n",
            "Epoch 166/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 182.2954 - val_loss: 220.9631\n",
            "Epoch 167/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 186.8873 - val_loss: 208.1174\n",
            "Epoch 168/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 206.5296 - val_loss: 216.6938\n",
            "Epoch 169/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 192.5643 - val_loss: 230.4059\n",
            "Epoch 170/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 201.0678 - val_loss: 205.5426\n",
            "Epoch 171/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 194.1303 - val_loss: 241.1055\n",
            "Epoch 172/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 195.5494 - val_loss: 214.2205\n",
            "Epoch 173/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 195.9469 - val_loss: 209.5211\n",
            "Epoch 174/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 189.1526 - val_loss: 229.0257\n",
            "Epoch 175/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 180.0785 - val_loss: 219.2147\n",
            "Epoch 176/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 210.4001 - val_loss: 249.0226\n",
            "Epoch 177/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 208.5456 - val_loss: 225.9521\n",
            "Epoch 178/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 201.0220 - val_loss: 263.6234\n",
            "Epoch 179/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 238.6994 - val_loss: 242.1438\n",
            "Epoch 180/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 213.2290 - val_loss: 219.8342\n",
            "Epoch 181/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 224.4704 - val_loss: 233.7928\n",
            "Epoch 182/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 181.9124 - val_loss: 226.3278\n",
            "Epoch 183/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 193.9972 - val_loss: 217.9636\n",
            "Epoch 184/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 192.5443 - val_loss: 210.0574\n",
            "Epoch 185/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 178.3149 - val_loss: 217.8266\n",
            "Epoch 186/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 189.9751 - val_loss: 207.6517\n",
            "Epoch 187/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 200.7102 - val_loss: 224.6521\n",
            "Epoch 188/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 189.5643 - val_loss: 228.9335\n",
            "Epoch 189/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 197.8941 - val_loss: 210.3160\n",
            "Epoch 190/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 194.3676 - val_loss: 216.5836\n",
            "Epoch 191/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 188.7467 - val_loss: 226.8968\n",
            "Epoch 192/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 196.3747 - val_loss: 210.5161\n",
            "Epoch 193/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 175.7002 - val_loss: 232.4443\n",
            "Epoch 194/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 207.4092 - val_loss: 219.7724\n",
            "Epoch 195/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 184.0923 - val_loss: 234.7675\n",
            "Epoch 196/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 188.3112 - val_loss: 234.9753\n",
            "Epoch 197/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 193.4483 - val_loss: 213.3555\n",
            "Epoch 198/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 173.6730 - val_loss: 215.2069\n",
            "Epoch 199/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 183.8135 - val_loss: 226.0729\n",
            "Epoch 200/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 202.8224 - val_loss: 242.4391\n",
            "Epoch 201/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 223.0615 - val_loss: 217.9833\n",
            "Epoch 202/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 197.0899 - val_loss: 254.2340\n",
            "Epoch 203/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 196.6014 - val_loss: 222.8795\n",
            "Epoch 204/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 178.5231 - val_loss: 205.6488\n",
            "Epoch 205/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 196.1147 - val_loss: 228.1110\n",
            "Epoch 206/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 194.4882 - val_loss: 212.6237\n",
            "Epoch 207/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 183.2007 - val_loss: 219.6347\n",
            "Epoch 208/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 191.7591 - val_loss: 220.8980\n",
            "Epoch 209/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 174.9253 - val_loss: 223.7818\n",
            "Epoch 210/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 181.2438 - val_loss: 211.8018\n",
            "Epoch 211/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 206.8183 - val_loss: 241.4251\n",
            "Epoch 212/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 194.3668 - val_loss: 238.6826\n",
            "Epoch 213/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 189.2307 - val_loss: 225.0086\n",
            "Epoch 214/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 180.1713 - val_loss: 217.5887\n",
            "Epoch 215/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 184.8085 - val_loss: 210.0073\n",
            "Epoch 216/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 190.8355 - val_loss: 222.7133\n",
            "Epoch 217/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 201.8850 - val_loss: 234.8469\n",
            "Epoch 218/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 196.7009 - val_loss: 212.6659\n",
            "Epoch 219/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 179.3397 - val_loss: 220.3848\n",
            "Epoch 220/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 181.3197 - val_loss: 214.1843\n",
            "Epoch 221/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 182.3380 - val_loss: 220.7769\n",
            "Epoch 222/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 185.8822 - val_loss: 215.9328\n",
            "Epoch 223/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 177.0058 - val_loss: 226.2061\n",
            "Epoch 224/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 178.3662 - val_loss: 213.5218\n",
            "Epoch 225/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 183.6408 - val_loss: 230.5479\n",
            "Epoch 226/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 182.9846 - val_loss: 217.7749\n",
            "Epoch 227/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 194.3591 - val_loss: 215.5563\n",
            "Epoch 228/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 201.4842 - val_loss: 231.3502\n",
            "Epoch 229/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 193.8994 - val_loss: 215.0053\n",
            "Epoch 230/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 212.0699 - val_loss: 213.2243\n",
            "Epoch 231/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 205.1416 - val_loss: 234.8394\n",
            "Epoch 232/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 199.9436 - val_loss: 216.8284\n",
            "Epoch 233/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 202.4933 - val_loss: 215.8812\n",
            "Epoch 234/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 195.3535 - val_loss: 206.9008\n",
            "Epoch 235/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 191.0450 - val_loss: 216.0227\n",
            "Epoch 236/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 209.2566 - val_loss: 244.0182\n",
            "Epoch 237/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 199.1190 - val_loss: 209.6684\n",
            "Epoch 238/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 188.3862 - val_loss: 226.7409\n",
            "Epoch 239/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 192.2238 - val_loss: 213.4507\n",
            "Epoch 240/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 181.3642 - val_loss: 209.8851\n",
            "Epoch 241/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 201.6376 - val_loss: 220.9203\n",
            "Epoch 242/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 197.9016 - val_loss: 235.4283\n",
            "Epoch 243/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 188.6606 - val_loss: 253.7041\n",
            "Epoch 244/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 219.3244 - val_loss: 272.1620\n",
            "Epoch 245/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 195.4213 - val_loss: 211.4036\n",
            "Epoch 246/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 199.4295 - val_loss: 213.8177\n",
            "Epoch 247/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 191.8974 - val_loss: 217.3510\n",
            "Epoch 248/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 190.6883 - val_loss: 223.2514\n",
            "Epoch 249/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 180.4415 - val_loss: 213.6350\n",
            "Epoch 250/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 175.2233 - val_loss: 211.5647\n",
            "Epoch 251/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 201.4784 - val_loss: 249.1627\n",
            "Epoch 252/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 182.2244 - val_loss: 213.4541\n",
            "Epoch 253/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 183.6384 - val_loss: 215.5964\n",
            "Epoch 254/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 186.7151 - val_loss: 210.5508\n",
            "Epoch 255/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 185.8085 - val_loss: 236.4464\n",
            "Epoch 256/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 197.2519 - val_loss: 209.9455\n",
            "Epoch 257/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 194.2452 - val_loss: 249.8925\n",
            "Epoch 258/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 189.5229 - val_loss: 220.5441\n",
            "Epoch 259/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 182.8914 - val_loss: 206.9770\n",
            "Epoch 260/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 183.5727 - val_loss: 220.8364\n",
            "Epoch 261/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 186.9172 - val_loss: 218.0528\n",
            "Epoch 262/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 190.9934 - val_loss: 236.1141\n",
            "Epoch 263/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 190.5382 - val_loss: 228.0056\n",
            "Epoch 264/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 182.4656 - val_loss: 215.2286\n",
            "Epoch 265/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 192.3044 - val_loss: 215.7873\n",
            "Epoch 266/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 188.3722 - val_loss: 209.7774\n",
            "Epoch 267/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 183.4762 - val_loss: 215.7498\n",
            "Epoch 268/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 188.8967 - val_loss: 255.2084\n",
            "Epoch 269/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 200.3856 - val_loss: 223.0656\n",
            "Epoch 270/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 195.7664 - val_loss: 213.0699\n",
            "Epoch 271/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 193.0583 - val_loss: 216.5057\n",
            "Epoch 272/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 189.9818 - val_loss: 210.8500\n",
            "Epoch 273/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 186.6138 - val_loss: 225.9226\n",
            "Epoch 274/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 175.1067 - val_loss: 234.5776\n",
            "Epoch 275/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 195.5964 - val_loss: 237.7710\n",
            "Epoch 276/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 184.0727 - val_loss: 219.4541\n",
            "Epoch 277/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 205.0316 - val_loss: 225.5485\n",
            "Epoch 278/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 190.7826 - val_loss: 228.7587\n",
            "Epoch 279/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 197.2685 - val_loss: 215.7641\n",
            "Epoch 280/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 192.8942 - val_loss: 235.8907\n",
            "Epoch 281/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 184.2647 - val_loss: 203.1013\n",
            "Epoch 282/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 218.3558 - val_loss: 241.7730\n",
            "Epoch 283/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 195.2292 - val_loss: 249.0773\n",
            "Epoch 284/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 182.7738 - val_loss: 206.7743\n",
            "Epoch 285/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 183.9495 - val_loss: 235.9200\n",
            "Epoch 286/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 187.5764 - val_loss: 205.2210\n",
            "Epoch 287/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 181.6359 - val_loss: 212.8435\n",
            "Epoch 288/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 181.5668 - val_loss: 232.0423\n",
            "Epoch 289/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 195.8943 - val_loss: 205.1863\n",
            "Epoch 290/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 185.1494 - val_loss: 224.4499\n",
            "Epoch 291/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 186.3347 - val_loss: 207.3879\n",
            "Epoch 292/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 213.7070 - val_loss: 220.8786\n",
            "Epoch 293/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 259.4134 - val_loss: 242.2402\n",
            "Epoch 294/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 191.2380 - val_loss: 235.1024\n",
            "Epoch 295/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 194.2780 - val_loss: 214.3331\n",
            "Epoch 296/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 183.5228 - val_loss: 220.4253\n",
            "Epoch 297/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 187.8548 - val_loss: 215.3699\n",
            "Epoch 298/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 186.9574 - val_loss: 244.0336\n",
            "Epoch 299/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 199.7207 - val_loss: 203.9135\n",
            "Epoch 300/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 177.0499 - val_loss: 217.5947\n",
            "Epoch 301/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 185.1802 - val_loss: 203.1802\n",
            "Epoch 302/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 175.5572 - val_loss: 202.5542\n",
            "Epoch 303/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 196.8359 - val_loss: 234.7188\n",
            "Epoch 304/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 192.4897 - val_loss: 202.9863\n",
            "Epoch 305/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 176.9778 - val_loss: 220.6593\n",
            "Epoch 306/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 180.0476 - val_loss: 211.7373\n",
            "Epoch 307/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 179.9624 - val_loss: 210.2946\n",
            "Epoch 308/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 195.0399 - val_loss: 238.8804\n",
            "Epoch 309/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 209.5970 - val_loss: 208.4271\n",
            "Epoch 310/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 211.2314 - val_loss: 222.8926\n",
            "Epoch 311/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 195.7021 - val_loss: 215.1411\n",
            "Epoch 312/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 186.4224 - val_loss: 225.2104\n",
            "Epoch 313/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 188.9469 - val_loss: 209.0535\n",
            "Epoch 314/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 192.5346 - val_loss: 210.4379\n",
            "Epoch 315/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 196.2663 - val_loss: 229.1525\n",
            "Epoch 316/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 179.9305 - val_loss: 211.0136\n",
            "Epoch 317/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 200.8154 - val_loss: 201.4623\n",
            "Epoch 318/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 187.9494 - val_loss: 203.1037\n",
            "Epoch 319/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 189.1493 - val_loss: 219.3873\n",
            "Epoch 320/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 186.2065 - val_loss: 213.9724\n",
            "Epoch 321/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 188.0457 - val_loss: 221.5650\n",
            "Epoch 322/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 179.4370 - val_loss: 202.2389\n",
            "Epoch 323/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 180.4205 - val_loss: 224.1069\n",
            "Epoch 324/500\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 177.0644 - val_loss: 205.7044\n",
            "Epoch 325/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 174.0758 - val_loss: 226.0908\n",
            "Epoch 326/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 181.7577 - val_loss: 205.1516\n",
            "Epoch 327/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 193.9704 - val_loss: 217.5057\n",
            "Epoch 328/500\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 180.1247 - val_loss: 257.3159\n",
            "Epoch 329/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 204.3507 - val_loss: 208.1065\n",
            "Epoch 330/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 205.4481 - val_loss: 209.1702\n",
            "Epoch 331/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 179.1635 - val_loss: 210.0544\n",
            "Epoch 332/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 173.6237 - val_loss: 214.7633\n",
            "Epoch 333/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 182.9973 - val_loss: 207.3231\n",
            "Epoch 334/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 197.3933 - val_loss: 222.2239\n",
            "Epoch 335/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 198.5485 - val_loss: 201.8828\n",
            "Epoch 336/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 193.6052 - val_loss: 209.7265\n",
            "Epoch 337/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 195.5185 - val_loss: 203.9675\n",
            "Epoch 338/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 188.4131 - val_loss: 231.2132\n",
            "Epoch 339/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 199.0683 - val_loss: 220.6798\n",
            "Epoch 340/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 189.7860 - val_loss: 212.9598\n",
            "Epoch 341/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 193.9695 - val_loss: 208.9434\n",
            "Epoch 342/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 200.2968 - val_loss: 216.4586\n",
            "Epoch 343/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 186.0859 - val_loss: 227.2714\n",
            "Epoch 344/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 199.7164 - val_loss: 223.9715\n",
            "Epoch 345/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 187.7088 - val_loss: 213.3615\n",
            "Epoch 346/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 193.1072 - val_loss: 206.9452\n",
            "Epoch 347/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 181.4931 - val_loss: 212.7481\n",
            "Epoch 348/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 200.3261 - val_loss: 218.3584\n",
            "Epoch 349/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 184.4982 - val_loss: 218.9644\n",
            "Epoch 350/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 180.8137 - val_loss: 218.3130\n",
            "Epoch 351/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 200.0877 - val_loss: 226.6006\n",
            "Epoch 352/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 192.2873 - val_loss: 210.4929\n",
            "Epoch 353/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 197.5560 - val_loss: 217.9351\n",
            "Epoch 354/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 184.2894 - val_loss: 222.2995\n",
            "Epoch 355/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 193.4043 - val_loss: 205.7040\n",
            "Epoch 356/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 189.3271 - val_loss: 210.7773\n",
            "Epoch 357/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 199.2417 - val_loss: 248.2422\n",
            "Epoch 358/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 213.4126 - val_loss: 226.9516\n",
            "Epoch 359/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 194.2088 - val_loss: 205.1835\n",
            "Epoch 360/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 194.0858 - val_loss: 212.7038\n",
            "Epoch 361/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 192.7089 - val_loss: 203.6298\n",
            "Epoch 362/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 182.8844 - val_loss: 237.5359\n",
            "Epoch 363/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 194.9241 - val_loss: 202.8332\n",
            "Epoch 364/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 188.1852 - val_loss: 225.4739\n",
            "Epoch 365/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 171.7980 - val_loss: 207.0969\n",
            "Epoch 366/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 182.7121 - val_loss: 216.6423\n",
            "Epoch 367/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 206.7938 - val_loss: 212.3494\n",
            "Epoch 368/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 186.3751 - val_loss: 220.7819\n",
            "Epoch 369/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 195.2714 - val_loss: 239.9832\n",
            "Epoch 370/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 222.9558 - val_loss: 215.0107\n",
            "Epoch 371/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 215.0553 - val_loss: 253.2919\n",
            "Epoch 372/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 212.4863 - val_loss: 214.9178\n",
            "Epoch 373/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 206.0453 - val_loss: 215.6948\n",
            "Epoch 374/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 223.1997 - val_loss: 251.6620\n",
            "Epoch 375/500\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 209.5789 - val_loss: 243.9385\n",
            "Epoch 376/500\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 200.3776 - val_loss: 211.5049\n",
            "Epoch 377/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 188.3853 - val_loss: 218.5417\n",
            "Epoch 378/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 182.0992 - val_loss: 216.0547\n",
            "Epoch 379/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 193.7638 - val_loss: 217.9389\n",
            "Epoch 380/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 192.1245 - val_loss: 213.1428\n",
            "Epoch 381/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 189.3475 - val_loss: 228.7589\n",
            "Epoch 382/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 173.7975 - val_loss: 216.8800\n",
            "Epoch 383/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 193.8923 - val_loss: 227.3839\n",
            "Epoch 384/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 204.6426 - val_loss: 208.8055\n",
            "Epoch 385/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 177.2137 - val_loss: 208.9947\n",
            "Epoch 386/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 187.2854 - val_loss: 229.6432\n",
            "Epoch 387/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 183.8105 - val_loss: 206.0437\n",
            "Epoch 388/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 184.2795 - val_loss: 223.7476\n",
            "Epoch 389/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 202.4759 - val_loss: 205.5126\n",
            "Epoch 390/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 201.8926 - val_loss: 242.1041\n",
            "Epoch 391/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 194.8457 - val_loss: 203.3793\n",
            "Epoch 392/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 195.4632 - val_loss: 214.9653\n",
            "Epoch 393/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 172.9614 - val_loss: 213.4821\n",
            "Epoch 394/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 176.2779 - val_loss: 220.9302\n",
            "Epoch 395/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 179.9113 - val_loss: 202.3668\n",
            "Epoch 396/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 192.5024 - val_loss: 238.6472\n",
            "Epoch 397/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 191.0705 - val_loss: 212.5462\n",
            "Epoch 398/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 183.6130 - val_loss: 236.9468\n",
            "Epoch 399/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 180.7404 - val_loss: 219.4131\n",
            "Epoch 400/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 194.1407 - val_loss: 218.9497\n",
            "Epoch 401/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 191.9736 - val_loss: 207.8920\n",
            "Epoch 402/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 199.9078 - val_loss: 229.4061\n",
            "Epoch 403/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 187.8955 - val_loss: 208.5124\n",
            "Epoch 404/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 193.6905 - val_loss: 221.6118\n",
            "Epoch 405/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 174.6223 - val_loss: 199.0356\n",
            "Epoch 406/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 173.1514 - val_loss: 215.3985\n",
            "Epoch 407/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 191.6247 - val_loss: 216.5497\n",
            "Epoch 408/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 216.7124 - val_loss: 207.2815\n",
            "Epoch 409/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 208.5188 - val_loss: 207.1624\n",
            "Epoch 410/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 166.9586 - val_loss: 223.3115\n",
            "Epoch 411/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 184.6975 - val_loss: 204.4073\n",
            "Epoch 412/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 173.7711 - val_loss: 220.1267\n",
            "Epoch 413/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 188.9973 - val_loss: 239.8646\n",
            "Epoch 414/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 183.1903 - val_loss: 205.6002\n",
            "Epoch 415/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 176.7900 - val_loss: 205.0671\n",
            "Epoch 416/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 199.6040 - val_loss: 207.8263\n",
            "Epoch 417/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 176.9086 - val_loss: 211.8093\n",
            "Epoch 418/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 189.2658 - val_loss: 211.2189\n",
            "Epoch 419/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 201.7448 - val_loss: 209.0253\n",
            "Epoch 420/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 172.7272 - val_loss: 214.9360\n",
            "Epoch 421/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 182.0421 - val_loss: 221.4819\n",
            "Epoch 422/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 189.8246 - val_loss: 216.4493\n",
            "Epoch 423/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 193.6519 - val_loss: 227.8302\n",
            "Epoch 424/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 187.4939 - val_loss: 210.1658\n",
            "Epoch 425/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 194.7629 - val_loss: 219.8973\n",
            "Epoch 426/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 187.2137 - val_loss: 229.3609\n",
            "Epoch 427/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 181.3797 - val_loss: 210.8301\n",
            "Epoch 428/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 213.3805 - val_loss: 234.4923\n",
            "Epoch 429/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 187.1104 - val_loss: 256.5812\n",
            "Epoch 430/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 199.2463 - val_loss: 209.4722\n",
            "Epoch 431/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 208.7988 - val_loss: 212.8148\n",
            "Epoch 432/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 205.7604 - val_loss: 238.6481\n",
            "Epoch 433/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 190.1042 - val_loss: 204.9065\n",
            "Epoch 434/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 197.0384 - val_loss: 220.4307\n",
            "Epoch 435/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 208.1759 - val_loss: 223.0643\n",
            "Epoch 436/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 185.1077 - val_loss: 211.9713\n",
            "Epoch 437/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 184.5369 - val_loss: 228.5264\n",
            "Epoch 438/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 182.1144 - val_loss: 204.1913\n",
            "Epoch 439/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 187.5852 - val_loss: 211.1397\n",
            "Epoch 440/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 191.8293 - val_loss: 242.0447\n",
            "Epoch 441/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 191.9966 - val_loss: 251.9194\n",
            "Epoch 442/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 193.4433 - val_loss: 213.8755\n",
            "Epoch 443/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 195.0722 - val_loss: 203.5503\n",
            "Epoch 444/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 188.8152 - val_loss: 205.5238\n",
            "Epoch 445/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 185.2921 - val_loss: 229.0810\n",
            "Epoch 446/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 176.2813 - val_loss: 230.1627\n",
            "Epoch 447/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 199.3783 - val_loss: 225.1717\n",
            "Epoch 448/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 177.6451 - val_loss: 209.0458\n",
            "Epoch 449/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 187.9978 - val_loss: 210.8455\n",
            "Epoch 450/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 186.3154 - val_loss: 203.8216\n",
            "Epoch 451/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 193.2060 - val_loss: 216.3184\n",
            "Epoch 452/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 187.1556 - val_loss: 243.3331\n",
            "Epoch 453/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 196.1911 - val_loss: 207.7630\n",
            "Epoch 454/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 193.4406 - val_loss: 224.1784\n",
            "Epoch 455/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 188.3970 - val_loss: 210.4538\n",
            "Epoch 456/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 180.6643 - val_loss: 216.3913\n",
            "Epoch 457/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 183.5185 - val_loss: 211.4995\n",
            "Epoch 458/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 182.7466 - val_loss: 218.9006\n",
            "Epoch 459/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 191.5737 - val_loss: 210.2683\n",
            "Epoch 460/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 213.2529 - val_loss: 250.3153\n",
            "Epoch 461/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 183.2608 - val_loss: 223.0121\n",
            "Epoch 462/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 192.1852 - val_loss: 216.2719\n",
            "Epoch 463/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 195.7873 - val_loss: 227.1347\n",
            "Epoch 464/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 194.0787 - val_loss: 232.6687\n",
            "Epoch 465/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 190.6235 - val_loss: 255.3837\n",
            "Epoch 466/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 224.9702 - val_loss: 212.7851\n",
            "Epoch 467/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 199.2630 - val_loss: 218.1165\n",
            "Epoch 468/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 182.0744 - val_loss: 231.9942\n",
            "Epoch 469/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 195.7722 - val_loss: 221.5290\n",
            "Epoch 470/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 189.3707 - val_loss: 222.9079\n",
            "Epoch 471/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 198.1833 - val_loss: 212.7547\n",
            "Epoch 472/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 186.7282 - val_loss: 230.4344\n",
            "Epoch 473/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 184.6334 - val_loss: 249.3205\n",
            "Epoch 474/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 212.4270 - val_loss: 208.8059\n",
            "Epoch 475/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 187.1446 - val_loss: 228.2281\n",
            "Epoch 476/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 198.8764 - val_loss: 243.7636\n",
            "Epoch 477/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 187.7626 - val_loss: 215.7288\n",
            "Epoch 478/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 190.9273 - val_loss: 208.9243\n",
            "Epoch 479/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 176.1932 - val_loss: 215.0322\n",
            "Epoch 480/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 188.7992 - val_loss: 209.3607\n",
            "Epoch 481/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 188.2538 - val_loss: 225.9755\n",
            "Epoch 482/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 191.0787 - val_loss: 220.0184\n",
            "Epoch 483/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 204.3555 - val_loss: 202.5070\n",
            "Epoch 484/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 181.3139 - val_loss: 239.1611\n",
            "Epoch 485/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 200.2109 - val_loss: 203.0700\n",
            "Epoch 486/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 189.1571 - val_loss: 225.1212\n",
            "Epoch 487/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 191.1266 - val_loss: 219.8015\n",
            "Epoch 488/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 184.6504 - val_loss: 210.6904\n",
            "Epoch 489/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 193.4214 - val_loss: 218.7512\n",
            "Epoch 490/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 173.0242 - val_loss: 209.0941\n",
            "Epoch 491/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 191.0168 - val_loss: 216.4939\n",
            "Epoch 492/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 189.9603 - val_loss: 229.2683\n",
            "Epoch 493/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 193.6661 - val_loss: 208.4861\n",
            "Epoch 494/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 191.7657 - val_loss: 217.6574\n",
            "Epoch 495/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 192.5420 - val_loss: 220.7508\n",
            "Epoch 496/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 188.2626 - val_loss: 233.5677\n",
            "Epoch 497/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 200.6939 - val_loss: 212.8491\n",
            "Epoch 498/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 192.8508 - val_loss: 247.2560\n",
            "Epoch 499/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 190.2553 - val_loss: 222.6502\n",
            "Epoch 500/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 192.8679 - val_loss: 209.2832\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faf05c5e590>"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ],
      "source": [
        "model.fit(x, t_m, validation_split=0.1, shuffle=True, batch_size=64, epochs=500)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.corrcoef(model(x)[:, 0].numpy(), t_m[:, 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joJT2sKKXXl9",
        "outputId": "cb9c8684-bbfc-450c-8d4b-1bb860b0699b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.00534385],\n",
              "       [0.00534385, 1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6aXsFft5v7N2"
      },
      "outputs": [],
      "source": [
        "\n",
        "hs_gpa = np.linspace(1, 6, 50)\n",
        "fy_gpa = np.linspace(1, 6, 50)\n",
        "zeros = np.zeros(50)\n",
        "ones = np.ones(50)\n",
        "\n",
        "sex_1 = np.stack([hs_gpa, zeros, zeros]).T\n",
        "sex_2 = np.stack([hs_gpa, zeros, ones]).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "Wb0qOZcXv7N3",
        "outputId": "e8618fea-a09b-41ce-e484-4ee5b09f61bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7faf05976ed0>]"
            ]
          },
          "metadata": {},
          "execution_count": 159
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(hs_gpa, model(sex_1)[:, 0])\n",
        "plt.plot(hs_gpa, model(sex_2)[:, 0])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0kR2l9JWF98e9G5AAuqu+",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}